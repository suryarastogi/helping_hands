{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"helping_hands","text":"<p>AI-powered repo builder \u2014 point it at a codebase, describe what you want, and let an AI agent help you build and ship features.</p> <p>For full project details, see the README.</p>"},{"location":"#api-reference","title":"API Reference","text":"<p>Browse the auto-generated docs from source:</p> <ul> <li>lib \u2014 Core library: config, repo, github, ai providers package, hands v1 package, meta tools package, meta tools.filesystem</li> <li>cli \u2014 CLI entry point: main</li> <li>server \u2014 App mode: app, celery_app, mcp_server, task_result</li> </ul>"},{"location":"#runtime-flow","title":"Runtime flow","text":"<ul> <li>Server mode: server enqueues a hand task, then the hand executes.</li> <li>App UI (<code>/</code>) can submit runs with backend/model/max-iterations/no-pr options.</li> <li>JS monitor path polls <code>/tasks/{task_id}</code> for live status/updates.</li> <li>No-JS fallback path redirects to <code>/monitor/{task_id}</code> (auto-refresh HTML monitor).</li> <li>CLI mode: CLI invokes the hand directly (index-only, E2E mode, or iterative basic backends).</li> <li><code>E2EHand</code> is the minimal concrete hand used to validate the full   clone/edit/commit/push/PR lifecycle.</li> <li>Optional <code>pr_number</code> lets the hand resume/update an existing PR branch.</li> <li>Basic iterative backends (<code>basic-langgraph</code>, <code>basic-atomic</code>, <code>basic-agent</code>)   stream multi-step output and, by default, attempt a final commit/push/PR step   unless disabled via <code>--no-pr</code>.</li> <li><code>codexcli</code> backend runs a two-phase CLI workflow:   initialization/learning pass, then task execution pass.</li> <li><code>codexcli</code> passes <code>--model gpt-5.2</code> by default when model is unset/default.</li> <li><code>codexcli</code> sets sandbox mode automatically:</li> <li>host: <code>workspace-write</code></li> <li>container: <code>danger-full-access</code> (to avoid landlock failures)</li> <li>override with <code>HELPING_HANDS_CODEX_SANDBOX_MODE</code>.</li> <li><code>codexcli</code> adds <code>--skip-git-repo-check</code> by default for non-interactive runs.</li> <li>Basic iterative hands preload iteration-1 context with <code>README.md</code>/<code>AGENT.md</code>   (when present) and a bounded-depth repo tree snapshot.</li> <li>Model selection resolves through <code>lib.ai_providers</code> wrappers, including   <code>provider/model</code> forms, before backend-specific model adaptation.</li> <li>Iterative/basic hands use shared system file tooling from <code>lib.meta.tools</code>   for repo-safe reads/writes and path validation.</li> <li>MCP now exposes filesystem tools backed by the same layer:   <code>read_file</code>, <code>write_file</code>, <code>mkdir</code>, and <code>path_exists</code>.</li> <li>CI test runs include coverage reporting and upload <code>coverage.xml</code> to Codecov   from the Python 3.12 job.</li> <li>Compose defaults include in-network Redis/Celery URLs for app-mode services   (<code>REDIS_URL</code>, <code>CELERY_BROKER_URL</code>, <code>CELERY_RESULT_BACKEND</code>).</li> </ul>"},{"location":"#codex-backend-requirements","title":"Codex backend requirements","text":"<ul> <li><code>codex</code> CLI installed and on <code>PATH</code>.</li> <li>Authenticated codex session in your shell (<code>codex login</code>) or equivalent key-based setup.</li> <li><code>GITHUB_TOKEN</code> or <code>GH_TOKEN</code> set if you want final commit/push/PR creation.</li> <li>Access to the model you request; if your codex default model is unavailable, pass <code>--model gpt-5.2</code>.</li> <li>Optional container mode is available via:</li> <li><code>HELPING_HANDS_CODEX_CONTAINER=1</code></li> <li><code>HELPING_HANDS_CODEX_CONTAINER_IMAGE=&lt;image-with-codex-cli&gt;</code></li> <li>You can disable automatic <code>--skip-git-repo-check</code> with:</li> <li><code>HELPING_HANDS_CODEX_SKIP_GIT_REPO_CHECK=0</code></li> <li>App mode supports <code>codexcli</code>; ensure the Celery worker environment has <code>codex</code> installed and authenticated.</li> <li>Docker app/worker images in this repo install <code>@openai/codex</code>; rebuild images after updates.</li> </ul> <p>Quick check:</p> <pre><code>codex exec --model gpt-5.2 \"Reply with READY and one sentence.\"\n</code></pre>"},{"location":"#cli-examples","title":"CLI examples","text":"<pre><code># basic-langgraph\nuv run helping-hands \"suryarastogi/helping_hands\" --backend basic-langgraph --model gpt-5.2 --prompt \"Implement one small safe improvement; if editing files use @@FILE blocks and end with SATISFIED: yes/no.\" --max-iterations 4\n\n# basic-atomic\nuv run helping-hands \"suryarastogi/helping_hands\" --backend basic-atomic --model gpt-5.2 --prompt \"Implement one small safe improvement; if editing files use @@FILE blocks and end with SATISFIED: yes/no.\" --max-iterations 4\n\n# basic-agent\nuv run helping-hands \"suryarastogi/helping_hands\" --backend basic-agent --model gpt-5.2 --prompt \"Implement one small safe improvement; if editing files use @@FILE blocks and end with SATISFIED: yes/no.\" --max-iterations 4\n\n# codexcli\nuv run helping-hands \"suryarastogi/helping_hands\" --backend codexcli --model gpt-5.2 --prompt \"Implement one small safe improvement\"\n\n# e2e (new PR)\nuv run helping-hands \"suryarastogi/helping_hands\" --e2e --prompt \"CI integration run: update PR on master\"\n\n# e2e (update existing PR #1)\nuv run helping-hands \"suryarastogi/helping_hands\" --e2e --pr-number 1 --prompt \"CI integration run: update PR on master\"\n</code></pre>"},{"location":"api/cli/main/","title":"cli.main","text":""},{"location":"api/cli/main/#helping_hands.cli.main","title":"<code>helping_hands.cli.main</code>","text":"<p>CLI entry point: parse args, load config, run the agent loop.</p>"},{"location":"api/cli/main/#helping_hands.cli.main.build_parser","title":"<code>build_parser()</code>","text":"<p>Build the argument parser for CLI mode.</p> Source code in <code>src/helping_hands/cli/main.py</code> <pre><code>def build_parser() -&gt; argparse.ArgumentParser:\n    \"\"\"Build the argument parser for CLI mode.\"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"helping-hands\",\n        description=\"AI-powered repo builder.\",\n    )\n    parser.add_argument(\n        \"repo\",\n        help=(\n            \"Local repository path (default mode) or GitHub owner/repo \"\n            \"when using --e2e.\"\n        ),\n    )\n    parser.add_argument(\n        \"--prompt\",\n        default=\"Analyze the repository and start implementing the requested task.\",\n        help=\"Prompt to pass to the selected hand.\",\n    )\n    parser.add_argument(\n        \"--pr-number\",\n        type=int,\n        default=None,\n        help=\"Optional existing PR number to resume/update in --e2e mode.\",\n    )\n    parser.add_argument(\n        \"--e2e\",\n        action=\"store_true\",\n        help=\"Run E2EHand flow: clone/edit/commit/push/PR.\",\n    )\n    parser.add_argument(\n        \"--backend\",\n        choices=(\"basic-langgraph\", \"basic-atomic\", \"basic-agent\", \"codexcli\"),\n        default=None,\n        help=\"Run an iterative coding hand in CLI mode.\",\n    )\n    parser.add_argument(\n        \"--max-iterations\",\n        type=int,\n        default=6,\n        help=\"Maximum iterations for basic hands.\",\n    )\n    parser.add_argument(\n        \"--no-pr\",\n        action=\"store_true\",\n        help=\"Disable final commit/push/PR step.\",\n    )\n    parser.add_argument(\n        \"--model\",\n        default=None,\n        help=\"AI model to use (overrides env/config).\",\n    )\n    parser.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        default=None,\n        help=\"Enable verbose output.\",\n    )\n    return parser\n</code></pre>"},{"location":"api/cli/main/#helping_hands.cli.main.main","title":"<code>main(argv=None)</code>","text":"<p>Entry point for the CLI.</p> Source code in <code>src/helping_hands/cli/main.py</code> <pre><code>def main(argv: list[str] | None = None) -&gt; None:\n    \"\"\"Entry point for the CLI.\"\"\"\n    parser = build_parser()\n    args = parser.parse_args(argv)\n\n    if args.e2e:\n        config = Config.from_env(\n            overrides={\"repo\": args.repo, \"model\": args.model, \"verbose\": args.verbose}\n        )\n        repo_index = RepoIndex(root=Path(config.repo or \".\"), files=[])\n        response = E2EHand(config, repo_index).run(\n            args.prompt,\n            pr_number=args.pr_number,\n            dry_run=args.no_pr,\n        )\n        print(response.message)\n        print(f\"hand_uuid={response.metadata.get('hand_uuid')}\")\n        print(f\"workspace={response.metadata.get('workspace')}\")\n        print(f\"pr_url={response.metadata.get('pr_url')}\")\n        return\n\n    try:\n        repo_path, cloned_from = _resolve_repo_path(args.repo)\n    except ValueError as exc:\n        print(f\"Error: {exc}\", file=sys.stderr)\n        sys.exit(1)\n    if cloned_from:\n        print(f\"Cloned {cloned_from} to {repo_path}\")\n\n    config = Config.from_env(\n        overrides={\"repo\": str(repo_path), \"model\": args.model, \"verbose\": args.verbose}\n    )\n    repo_index = RepoIndex.from_path(Path(config.repo))\n\n    if args.backend:\n        hand: Hand\n        try:\n            if args.backend == \"basic-langgraph\":\n                hand = BasicLangGraphHand(\n                    config,\n                    repo_index,\n                    max_iterations=args.max_iterations,\n                )\n            elif args.backend == \"codexcli\":\n                hand = CodexCLIHand(config, repo_index)\n            else:\n                hand = BasicAtomicHand(\n                    config,\n                    repo_index,\n                    max_iterations=args.max_iterations,\n                )\n            hand.auto_pr = not args.no_pr\n        except ModuleNotFoundError as exc:\n            extra = \"langchain\" if args.backend == \"basic-langgraph\" else \"atomic\"\n            if args.backend in {\"basic-atomic\", \"basic-agent\"} and sys.version_info &lt; (\n                3,\n                12,\n            ):\n                print(\n                    (\n                        f\"Error: --backend {args.backend} requires Python &gt;= 3.12. \"\n                        \"Current Python is \"\n                        f\"{sys.version_info.major}.{sys.version_info.minor}. \"\n                        \"Re-run with Python 3.12+, e.g. \"\n                        \"'uv sync --python 3.12 --dev --extra atomic' and \"\n                        \"'uv run --python 3.12 helping-hands ...'\"\n                    ),\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n            print(\n                (\n                    f\"Error: missing dependency for --backend {args.backend}: {exc}. \"\n                    f\"Install with: uv sync --extra {extra}\"\n                ),\n                file=sys.stderr,\n            )\n            sys.exit(1)\n        try:\n            asyncio.run(_stream_hand(hand, args.prompt))\n        except KeyboardInterrupt:\n            hand.interrupt()\n            print(\"\\nInterrupted by user.\")\n        except Exception as exc:\n            msg = str(exc)\n            if \"model_not_found\" in msg or \"does not exist\" in msg:\n                print(\n                    (\n                        f\"Error: model {config.model!r} is not available. \"\n                        \"Pass a valid model via --model (or HELPING_HANDS_MODEL), \"\n                        \"for example: --model gpt-5.2\"\n                    ),\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n            if args.backend == \"codexcli\":\n                print(f\"Error: {msg}\", file=sys.stderr)\n                sys.exit(1)\n            raise\n        return\n\n    n = len(repo_index.files)\n    s = \"s\" if n != 1 else \"\"\n    print(f\"Ready. Indexed {n} file{s} in {repo_index.root}.\")\n</code></pre>"},{"location":"api/lib/ai_providers/","title":"lib.ai_providers (package)","text":""},{"location":"api/lib/ai_providers/#helping_hands.lib.ai_providers","title":"<code>helping_hands.lib.ai_providers</code>","text":"<p>Provider wrapper layer for AI backends used by hands.</p> <p>This package sits alongside <code>helping_hands.lib.hands</code> and provides a stable namespace for provider-specific wrappers and defaults.</p> <p>Related interfaces: - Used by hand/backends that need provider-level invocation and defaults. - Referenced by CLI/server code to resolve provider implementations.</p>"},{"location":"api/lib/ai_providers/#helping_hands.lib.ai_providers.AnthropicProvider","title":"<code>AnthropicProvider</code>","text":"<p>               Bases: <code>AIProvider</code></p> <p>Wrapper around the Anthropic Python SDK client.</p> Source code in <code>src/helping_hands/lib/ai_providers/anthropic.py</code> <pre><code>class AnthropicProvider(AIProvider):\n    \"\"\"Wrapper around the Anthropic Python SDK client.\"\"\"\n\n    name = \"anthropic\"\n    api_key_env_var = \"ANTHROPIC_API_KEY\"\n    default_model = \"claude-3-5-sonnet-latest\"\n    install_hint = \"uv add anthropic\"\n\n    def _build_inner(self) -&gt; Any:\n        try:\n            from anthropic import Anthropic\n        except ImportError as exc:\n            raise RuntimeError(\n                \"Anthropic SDK is not installed. Install with: uv add anthropic\"\n            ) from exc\n\n        api_key = os.environ.get(self.api_key_env_var)\n        if api_key:\n            return Anthropic(api_key=api_key)\n        return Anthropic()\n\n    def _complete_impl(\n        self,\n        *,\n        inner: Any,\n        messages: list[dict[str, str]],\n        model: str,\n        **kwargs: Any,\n    ) -&gt; Any:\n        max_tokens = kwargs.pop(\"max_tokens\", 1024)\n        return inner.messages.create(\n            model=model,\n            max_tokens=max_tokens,\n            messages=messages,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/lib/ai_providers/#helping_hands.lib.ai_providers.GoogleProvider","title":"<code>GoogleProvider</code>","text":"<p>               Bases: <code>AIProvider</code></p> <p>Wrapper around the Google GenAI Python SDK client.</p> Source code in <code>src/helping_hands/lib/ai_providers/google.py</code> <pre><code>class GoogleProvider(AIProvider):\n    \"\"\"Wrapper around the Google GenAI Python SDK client.\"\"\"\n\n    name = \"google\"\n    api_key_env_var = \"GOOGLE_API_KEY\"\n    default_model = \"gemini-2.0-flash\"\n    install_hint = \"uv add google-genai\"\n\n    def _build_inner(self) -&gt; Any:\n        try:\n            from google import genai\n        except ImportError as exc:\n            raise RuntimeError(\n                \"Google GenAI SDK is not installed. Install with: uv add google-genai\"\n            ) from exc\n\n        api_key = os.environ.get(self.api_key_env_var)\n        if api_key:\n            return genai.Client(api_key=api_key)\n        return genai.Client()\n\n    def _complete_impl(\n        self,\n        *,\n        inner: Any,\n        messages: list[dict[str, str]],\n        model: str,\n        **kwargs: Any,\n    ) -&gt; Any:\n        contents = [m[\"content\"] for m in messages if m[\"content\"]]\n        return inner.models.generate_content(\n            model=model,\n            contents=contents,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/lib/ai_providers/#helping_hands.lib.ai_providers.LiteLLMProvider","title":"<code>LiteLLMProvider</code>","text":"<p>               Bases: <code>AIProvider</code></p> <p>Wrapper around the LiteLLM Python package.</p> Source code in <code>src/helping_hands/lib/ai_providers/litellm.py</code> <pre><code>class LiteLLMProvider(AIProvider):\n    \"\"\"Wrapper around the LiteLLM Python package.\"\"\"\n\n    name = \"litellm\"\n    api_key_env_var = \"LITELLM_API_KEY\"\n    default_model = \"gpt-5.2\"\n    install_hint = \"uv add litellm\"\n\n    def _build_inner(self) -&gt; Any:\n        try:\n            import litellm\n        except ImportError as exc:\n            raise RuntimeError(\n                \"LiteLLM is not installed. Install with: uv add litellm\"\n            ) from exc\n\n        api_key = os.environ.get(self.api_key_env_var)\n        if api_key:\n            litellm.api_key = api_key\n        return litellm\n\n    def _complete_impl(\n        self,\n        *,\n        inner: Any,\n        messages: list[dict[str, str]],\n        model: str,\n        **kwargs: Any,\n    ) -&gt; Any:\n        return inner.completion(\n            model=model,\n            messages=messages,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/lib/ai_providers/#helping_hands.lib.ai_providers.OpenAIProvider","title":"<code>OpenAIProvider</code>","text":"<p>               Bases: <code>AIProvider</code></p> <p>Wrapper around the OpenAI Python SDK client.</p> Source code in <code>src/helping_hands/lib/ai_providers/openai.py</code> <pre><code>class OpenAIProvider(AIProvider):\n    \"\"\"Wrapper around the OpenAI Python SDK client.\"\"\"\n\n    name = \"openai\"\n    api_key_env_var = \"OPENAI_API_KEY\"\n    default_model = \"gpt-5.2\"\n    install_hint = \"uv add openai\"\n\n    def _build_inner(self) -&gt; Any:\n        try:\n            from openai import OpenAI\n        except ImportError as exc:\n            raise RuntimeError(\n                \"OpenAI SDK is not installed. Install with: uv add openai\"\n            ) from exc\n\n        api_key = os.environ.get(self.api_key_env_var)\n        if api_key:\n            return OpenAI(api_key=api_key)\n        return OpenAI()\n\n    def _complete_impl(\n        self,\n        *,\n        inner: Any,\n        messages: list[dict[str, str]],\n        model: str,\n        **kwargs: Any,\n    ) -&gt; Any:\n        return inner.responses.create(\n            model=model,\n            input=messages,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/lib/ai_providers/#helping_hands.lib.ai_providers.AIProvider","title":"<code>AIProvider</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Common provider wrapper interface with lazy inner client loading.</p> Source code in <code>src/helping_hands/lib/ai_providers/types.py</code> <pre><code>class AIProvider(abc.ABC):\n    \"\"\"Common provider wrapper interface with lazy inner client loading.\"\"\"\n\n    name: str\n    api_key_env_var: str\n    default_model: str\n\n    def __init__(self, *, inner: Any | None = None) -&gt; None:\n        self._inner = inner\n\n    @property\n    def inner(self) -&gt; Any:\n        \"\"\"Provider-specific underlying SDK object.\"\"\"\n        if self._inner is None:\n            self._inner = self._build_inner()\n        return self._inner\n\n    @property\n    @abc.abstractmethod\n    def install_hint(self) -&gt; str:\n        \"\"\"Human-readable dependency install hint.\"\"\"\n\n    @abc.abstractmethod\n    def _build_inner(self) -&gt; Any:\n        \"\"\"Construct the provider-specific SDK client/module.\"\"\"\n\n    @abc.abstractmethod\n    def _complete_impl(\n        self,\n        *,\n        inner: Any,\n        messages: list[dict[str, str]],\n        model: str,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Provider-specific completion call implementation.\"\"\"\n\n    def complete(\n        self,\n        prompt_or_messages: PromptInput,\n        *,\n        model: str | None = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Run a completion call using the provider-specific implementation.\"\"\"\n        messages = normalize_messages(prompt_or_messages)\n        resolved_model = model or self.default_model\n        return self._complete_impl(\n            inner=self.inner,\n            messages=messages,\n            model=resolved_model,\n            **kwargs,\n        )\n\n    async def acomplete(\n        self,\n        prompt_or_messages: PromptInput,\n        *,\n        model: str | None = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Async completion wrapper around ``complete``.\"\"\"\n        return await asyncio.to_thread(\n            self.complete,\n            prompt_or_messages,\n            model=model,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/lib/ai_providers/#helping_hands.lib.ai_providers.AIProvider.inner","title":"<code>inner</code>  <code>property</code>","text":"<p>Provider-specific underlying SDK object.</p>"},{"location":"api/lib/ai_providers/#helping_hands.lib.ai_providers.AIProvider.install_hint","title":"<code>install_hint</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Human-readable dependency install hint.</p>"},{"location":"api/lib/ai_providers/#helping_hands.lib.ai_providers.AIProvider.complete","title":"<code>complete(prompt_or_messages, *, model=None, **kwargs)</code>","text":"<p>Run a completion call using the provider-specific implementation.</p> Source code in <code>src/helping_hands/lib/ai_providers/types.py</code> <pre><code>def complete(\n    self,\n    prompt_or_messages: PromptInput,\n    *,\n    model: str | None = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Run a completion call using the provider-specific implementation.\"\"\"\n    messages = normalize_messages(prompt_or_messages)\n    resolved_model = model or self.default_model\n    return self._complete_impl(\n        inner=self.inner,\n        messages=messages,\n        model=resolved_model,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/lib/ai_providers/#helping_hands.lib.ai_providers.AIProvider.acomplete","title":"<code>acomplete(prompt_or_messages, *, model=None, **kwargs)</code>  <code>async</code>","text":"<p>Async completion wrapper around <code>complete</code>.</p> Source code in <code>src/helping_hands/lib/ai_providers/types.py</code> <pre><code>async def acomplete(\n    self,\n    prompt_or_messages: PromptInput,\n    *,\n    model: str | None = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Async completion wrapper around ``complete``.\"\"\"\n    return await asyncio.to_thread(\n        self.complete,\n        prompt_or_messages,\n        model=model,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/lib/config/","title":"config","text":""},{"location":"api/lib/config/#helping_hands.lib.config","title":"<code>helping_hands.lib.config</code>","text":"<p>Configuration loading: CLI flags \u2192 env vars \u2192 TOML file.</p>"},{"location":"api/lib/config/#helping_hands.lib.config.Config","title":"<code>Config</code>  <code>dataclass</code>","text":"<p>Immutable application configuration.</p> Source code in <code>src/helping_hands/lib/config.py</code> <pre><code>@dataclass(frozen=True)\nclass Config:\n    \"\"\"Immutable application configuration.\"\"\"\n\n    repo: str = \"\"\n    model: str = \"default\"\n    verbose: bool = False\n    config_path: Path | None = None\n\n    @classmethod\n    def from_env(cls, overrides: dict[str, str | bool | None] | None = None) -&gt; Config:\n        \"\"\"Build config from environment variables, then apply overrides.\n\n        Priority: overrides (CLI flags) &gt; env vars &gt; defaults.\n        \"\"\"\n        repo_override = overrides.get(\"repo\") if overrides else None\n        _load_env_files(str(repo_override) if isinstance(repo_override, str) else None)\n\n        env_values: dict[str, str | bool | None] = {\n            \"model\": os.environ.get(\"HELPING_HANDS_MODEL\"),\n            \"verbose\": os.environ.get(\"HELPING_HANDS_VERBOSE\", \"\").lower()\n            in (\"1\", \"true\", \"yes\"),\n        }\n\n        merged = {k: v for k, v in env_values.items() if v}\n        if overrides:\n            merged.update({k: v for k, v in overrides.items() if v is not None})\n\n        return cls(\n            repo=str(merged.get(\"repo\", cls.repo)),\n            model=str(merged.get(\"model\", cls.model)),\n            verbose=bool(merged.get(\"verbose\", cls.verbose)),\n        )\n</code></pre>"},{"location":"api/lib/config/#helping_hands.lib.config.Config.from_env","title":"<code>from_env(overrides=None)</code>  <code>classmethod</code>","text":"<p>Build config from environment variables, then apply overrides.</p> <p>Priority: overrides (CLI flags) &gt; env vars &gt; defaults.</p> Source code in <code>src/helping_hands/lib/config.py</code> <pre><code>@classmethod\ndef from_env(cls, overrides: dict[str, str | bool | None] | None = None) -&gt; Config:\n    \"\"\"Build config from environment variables, then apply overrides.\n\n    Priority: overrides (CLI flags) &gt; env vars &gt; defaults.\n    \"\"\"\n    repo_override = overrides.get(\"repo\") if overrides else None\n    _load_env_files(str(repo_override) if isinstance(repo_override, str) else None)\n\n    env_values: dict[str, str | bool | None] = {\n        \"model\": os.environ.get(\"HELPING_HANDS_MODEL\"),\n        \"verbose\": os.environ.get(\"HELPING_HANDS_VERBOSE\", \"\").lower()\n        in (\"1\", \"true\", \"yes\"),\n    }\n\n    merged = {k: v for k, v in env_values.items() if v}\n    if overrides:\n        merged.update({k: v for k, v in overrides.items() if v is not None})\n\n    return cls(\n        repo=str(merged.get(\"repo\", cls.repo)),\n        model=str(merged.get(\"model\", cls.model)),\n        verbose=bool(merged.get(\"verbose\", cls.verbose)),\n    )\n</code></pre>"},{"location":"api/lib/github/","title":"github","text":""},{"location":"api/lib/github/#helping_hands.lib.github","title":"<code>helping_hands.lib.github</code>","text":"<p>GitHub integration: auth, clone, branch, commit, and pull requests.</p> <p>This module is designed to be used by agents (hands) as a tool/skill. It wraps PyGithub for the API and subprocess git for local operations.</p>"},{"location":"api/lib/github/#helping_hands.lib.github.PRResult","title":"<code>PRResult</code>  <code>dataclass</code>","text":"<p>Result of creating a pull request.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>@dataclass\nclass PRResult:\n    \"\"\"Result of creating a pull request.\"\"\"\n\n    number: int\n    url: str\n    title: str\n    head: str\n    base: str\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient","title":"<code>GitHubClient</code>  <code>dataclass</code>","text":"<p>Authenticated GitHub client for repo operations.</p> <p>Supports token auth (PAT or fine-grained) and GitHub App installation tokens. The token is read from the <code>token</code> field, or falls back to the <code>GITHUB_TOKEN</code> / <code>GH_TOKEN</code> environment variable.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>@dataclass\nclass GitHubClient:\n    \"\"\"Authenticated GitHub client for repo operations.\n\n    Supports token auth (PAT or fine-grained) and GitHub App installation\n    tokens. The token is read from the ``token`` field, or falls back to\n    the ``GITHUB_TOKEN`` / ``GH_TOKEN`` environment variable.\n    \"\"\"\n\n    token: str = \"\"\n    _gh: Github = field(init=False, repr=False)\n\n    def __post_init__(self) -&gt; None:\n        resolved = self.token or os.environ.get(\n            \"GITHUB_TOKEN\", os.environ.get(\"GH_TOKEN\", \"\")\n        )\n        if not resolved:\n            msg = (\n                \"No GitHub token provided. Set GITHUB_TOKEN or GH_TOKEN, \"\n                \"or pass token= explicitly.\"\n            )\n            raise ValueError(msg)\n        self.token = resolved\n        self._gh = Github(auth=Auth.Token(self.token))\n\n    # ------------------------------------------------------------------\n    # Auth / identity\n    # ------------------------------------------------------------------\n\n    def whoami(self) -&gt; dict[str, Any]:\n        \"\"\"Return the authenticated user's login and name.\"\"\"\n        user = self._gh.get_user()\n        return {\"login\": user.login, \"name\": user.name, \"url\": user.html_url}\n\n    # ------------------------------------------------------------------\n    # Repository\n    # ------------------------------------------------------------------\n\n    def get_repo(self, full_name: str) -&gt; Repository:\n        \"\"\"Get a repository by owner/name (e.g. ``\"suryarastogi/helping_hands\"``).\"\"\"\n        return self._gh.get_repo(full_name)\n\n    # ------------------------------------------------------------------\n    # Clone\n    # ------------------------------------------------------------------\n\n    def clone(\n        self,\n        full_name: str,\n        dest: Path | str,\n        *,\n        branch: str | None = None,\n        depth: int | None = 1,\n    ) -&gt; Path:\n        \"\"\"Clone a repo to *dest* using the authenticated token for HTTPS.\n\n        Args:\n            full_name: ``owner/repo`` string.\n            dest: Local directory to clone into. Created if it doesn't exist.\n            branch: Optional branch to check out.\n            depth: Shallow clone depth. ``None`` for full history.\n\n        Returns:\n            Path to the cloned repository.\n        \"\"\"\n        dest = Path(dest)\n        url = f\"https://x-access-token:{self.token}@github.com/{full_name}.git\"\n        cmd: list[str] = [\"git\", \"clone\"]\n        if depth is not None:\n            cmd += [\"--depth\", str(depth)]\n        if branch:\n            cmd += [\"--branch\", branch]\n        cmd += [url, str(dest)]\n        _run_git(cmd)\n        logger.info(\"Cloned %s \u2192 %s\", full_name, dest)\n        return dest\n\n    # ------------------------------------------------------------------\n    # Branch\n    # ------------------------------------------------------------------\n\n    @staticmethod\n    def create_branch(repo_path: Path | str, branch_name: str) -&gt; None:\n        \"\"\"Create and switch to a new branch in a local repo.\"\"\"\n        _run_git([\"git\", \"checkout\", \"-b\", branch_name], cwd=repo_path)\n\n    @staticmethod\n    def switch_branch(repo_path: Path | str, branch_name: str) -&gt; None:\n        \"\"\"Switch to an existing branch.\"\"\"\n        _run_git([\"git\", \"checkout\", branch_name], cwd=repo_path)\n\n    @staticmethod\n    def fetch_branch(\n        repo_path: Path | str,\n        branch_name: str,\n        *,\n        remote: str = \"origin\",\n    ) -&gt; None:\n        \"\"\"Fetch a remote branch into a matching local branch name.\"\"\"\n        _run_git(\n            [\n                \"git\",\n                \"fetch\",\n                remote,\n                f\"refs/heads/{branch_name}:refs/heads/{branch_name}\",\n            ],\n            cwd=repo_path,\n        )\n\n    @staticmethod\n    def current_branch(repo_path: Path | str) -&gt; str:\n        \"\"\"Return the name of the current branch.\"\"\"\n        result = _run_git([\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=repo_path)\n        return result.stdout.strip()\n\n    # ------------------------------------------------------------------\n    # Commit\n    # ------------------------------------------------------------------\n\n    @staticmethod\n    def add_and_commit(\n        repo_path: Path | str,\n        message: str,\n        *,\n        paths: list[str] | None = None,\n    ) -&gt; str:\n        \"\"\"Stage files and commit. Returns the commit SHA.\n\n        Args:\n            repo_path: Local repo directory.\n            message: Commit message.\n            paths: Specific paths to ``git add``. Defaults to ``[\".\"]`` (all).\n\n        Returns:\n            The short SHA of the new commit.\n        \"\"\"\n        targets = paths or [\".\"]\n        _run_git([\"git\", \"add\", *targets], cwd=repo_path)\n        _run_git([\"git\", \"commit\", \"-m\", message], cwd=repo_path)\n        result = _run_git([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], cwd=repo_path)\n        return result.stdout.strip()\n\n    @staticmethod\n    def set_local_identity(\n        repo_path: Path | str,\n        *,\n        name: str,\n        email: str,\n    ) -&gt; None:\n        \"\"\"Set git author identity in local repo config.\"\"\"\n        _run_git([\"git\", \"config\", \"user.name\", name], cwd=repo_path)\n        _run_git([\"git\", \"config\", \"user.email\", email], cwd=repo_path)\n\n    # ------------------------------------------------------------------\n    # Push\n    # ------------------------------------------------------------------\n\n    def push(\n        self,\n        repo_path: Path | str,\n        *,\n        remote: str = \"origin\",\n        branch: str | None = None,\n        set_upstream: bool = True,\n    ) -&gt; None:\n        \"\"\"Push the current branch to the remote.\n\n        Args:\n            repo_path: Local repo directory.\n            remote: Remote name.\n            branch: Branch to push. Defaults to current branch.\n            set_upstream: If True, set the upstream tracking ref.\n        \"\"\"\n        branch = branch or self.current_branch(repo_path)\n        cmd = [\"git\", \"push\"]\n        if set_upstream:\n            cmd += [\"-u\", remote, branch]\n        else:\n            cmd += [remote, branch]\n        _run_git(cmd, cwd=repo_path)\n\n    # ------------------------------------------------------------------\n    # Pull request\n    # ------------------------------------------------------------------\n\n    def create_pr(\n        self,\n        full_name: str,\n        *,\n        title: str,\n        body: str = \"\",\n        head: str,\n        base: str = \"main\",\n        draft: bool = False,\n    ) -&gt; PRResult:\n        \"\"\"Create a pull request on GitHub.\n\n        Args:\n            full_name: ``owner/repo`` string.\n            title: PR title.\n            body: PR body (markdown).\n            head: Source branch name.\n            base: Target branch name.\n            draft: Whether to create as a draft PR.\n\n        Returns:\n            A ``PRResult`` with the PR number, URL, title, head, and base.\n        \"\"\"\n        repo = self.get_repo(full_name)\n        pr: PullRequest = repo.create_pull(\n            title=title, body=body, head=head, base=base, draft=draft\n        )\n        logger.info(\"Created PR #%d: %s\", pr.number, pr.html_url)\n        return PRResult(\n            number=pr.number,\n            url=pr.html_url,\n            title=pr.title,\n            head=head,\n            base=base,\n        )\n\n    # ------------------------------------------------------------------\n    # PR helpers\n    # ------------------------------------------------------------------\n\n    def list_prs(\n        self,\n        full_name: str,\n        *,\n        state: str = \"open\",\n        limit: int = 30,\n    ) -&gt; list[dict[str, Any]]:\n        \"\"\"List pull requests for a repo.\n\n        Args:\n            full_name: ``owner/repo`` string.\n            state: ``\"open\"``, ``\"closed\"``, or ``\"all\"``.\n            limit: Maximum number of PRs to return.\n        \"\"\"\n        repo = self.get_repo(full_name)\n        prs: list[PullRequest] = list(\n            repo.get_pulls(state=state, sort=\"created\", direction=\"desc\")\n        )[:limit]\n        return [\n            {\n                \"number\": pr.number,\n                \"title\": pr.title,\n                \"url\": pr.html_url,\n                \"state\": pr.state,\n                \"head\": pr.head.ref,\n                \"base\": pr.base.ref,\n            }\n            for pr in prs\n        ]\n\n    def get_pr(self, full_name: str, number: int) -&gt; dict[str, Any]:\n        \"\"\"Get details of a single pull request.\"\"\"\n        repo = self.get_repo(full_name)\n        pr = repo.get_pull(number)\n        return {\n            \"number\": pr.number,\n            \"title\": pr.title,\n            \"body\": pr.body,\n            \"url\": pr.html_url,\n            \"state\": pr.state,\n            \"head\": pr.head.ref,\n            \"base\": pr.base.ref,\n            \"mergeable\": pr.mergeable,\n            \"merged\": pr.merged,\n        }\n\n    def default_branch(self, full_name: str) -&gt; str:\n        \"\"\"Return the repository's default branch.\"\"\"\n        repo = self.get_repo(full_name)\n        return str(repo.default_branch)\n\n    def update_pr_body(self, full_name: str, number: int, *, body: str) -&gt; None:\n        \"\"\"Update the body/description of an existing pull request.\"\"\"\n        repo = self.get_repo(full_name)\n        pr = repo.get_pull(number)\n        pr.edit(body=body)\n\n    def upsert_pr_comment(\n        self,\n        full_name: str,\n        number: int,\n        *,\n        body: str,\n        marker: str = \"&lt;!-- helping_hands:status --&gt;\",\n    ) -&gt; int:\n        \"\"\"Create or update a marker-tagged PR comment.\n\n        If a comment containing ``marker`` already exists, it is edited in place.\n        Otherwise, a new comment is created.\n        \"\"\"\n        repo = self.get_repo(full_name)\n        issue = repo.get_issue(number=number)\n        comment_body = body.rstrip()\n        if marker and marker not in comment_body:\n            comment_body = f\"{comment_body}\\n\\n{marker}\"\n\n        for comment in issue.get_comments():\n            existing = comment.body or \"\"\n            if marker and marker in existing:\n                comment.edit(comment_body)\n                return int(comment.id)\n\n        created = issue.create_comment(comment_body)\n        return int(created.id)\n\n    # ------------------------------------------------------------------\n    # Cleanup\n    # ------------------------------------------------------------------\n\n    def close(self) -&gt; None:\n        \"\"\"Close the underlying GitHub connection.\"\"\"\n        self._gh.close()\n\n    def __enter__(self) -&gt; GitHubClient:\n        return self\n\n    def __exit__(self, *_: Any) -&gt; None:\n        self.close()\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.whoami","title":"<code>whoami()</code>","text":"<p>Return the authenticated user's login and name.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def whoami(self) -&gt; dict[str, Any]:\n    \"\"\"Return the authenticated user's login and name.\"\"\"\n    user = self._gh.get_user()\n    return {\"login\": user.login, \"name\": user.name, \"url\": user.html_url}\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.get_repo","title":"<code>get_repo(full_name)</code>","text":"<p>Get a repository by owner/name (e.g. <code>\"suryarastogi/helping_hands\"</code>).</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def get_repo(self, full_name: str) -&gt; Repository:\n    \"\"\"Get a repository by owner/name (e.g. ``\"suryarastogi/helping_hands\"``).\"\"\"\n    return self._gh.get_repo(full_name)\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.clone","title":"<code>clone(full_name, dest, *, branch=None, depth=1)</code>","text":"<p>Clone a repo to dest using the authenticated token for HTTPS.</p> <p>Parameters:</p> Name Type Description Default <code>full_name</code> <code>str</code> <p><code>owner/repo</code> string.</p> required <code>dest</code> <code>Path | str</code> <p>Local directory to clone into. Created if it doesn't exist.</p> required <code>branch</code> <code>str | None</code> <p>Optional branch to check out.</p> <code>None</code> <code>depth</code> <code>int | None</code> <p>Shallow clone depth. <code>None</code> for full history.</p> <code>1</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the cloned repository.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def clone(\n    self,\n    full_name: str,\n    dest: Path | str,\n    *,\n    branch: str | None = None,\n    depth: int | None = 1,\n) -&gt; Path:\n    \"\"\"Clone a repo to *dest* using the authenticated token for HTTPS.\n\n    Args:\n        full_name: ``owner/repo`` string.\n        dest: Local directory to clone into. Created if it doesn't exist.\n        branch: Optional branch to check out.\n        depth: Shallow clone depth. ``None`` for full history.\n\n    Returns:\n        Path to the cloned repository.\n    \"\"\"\n    dest = Path(dest)\n    url = f\"https://x-access-token:{self.token}@github.com/{full_name}.git\"\n    cmd: list[str] = [\"git\", \"clone\"]\n    if depth is not None:\n        cmd += [\"--depth\", str(depth)]\n    if branch:\n        cmd += [\"--branch\", branch]\n    cmd += [url, str(dest)]\n    _run_git(cmd)\n    logger.info(\"Cloned %s \u2192 %s\", full_name, dest)\n    return dest\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.create_branch","title":"<code>create_branch(repo_path, branch_name)</code>  <code>staticmethod</code>","text":"<p>Create and switch to a new branch in a local repo.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>@staticmethod\ndef create_branch(repo_path: Path | str, branch_name: str) -&gt; None:\n    \"\"\"Create and switch to a new branch in a local repo.\"\"\"\n    _run_git([\"git\", \"checkout\", \"-b\", branch_name], cwd=repo_path)\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.switch_branch","title":"<code>switch_branch(repo_path, branch_name)</code>  <code>staticmethod</code>","text":"<p>Switch to an existing branch.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>@staticmethod\ndef switch_branch(repo_path: Path | str, branch_name: str) -&gt; None:\n    \"\"\"Switch to an existing branch.\"\"\"\n    _run_git([\"git\", \"checkout\", branch_name], cwd=repo_path)\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.fetch_branch","title":"<code>fetch_branch(repo_path, branch_name, *, remote='origin')</code>  <code>staticmethod</code>","text":"<p>Fetch a remote branch into a matching local branch name.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>@staticmethod\ndef fetch_branch(\n    repo_path: Path | str,\n    branch_name: str,\n    *,\n    remote: str = \"origin\",\n) -&gt; None:\n    \"\"\"Fetch a remote branch into a matching local branch name.\"\"\"\n    _run_git(\n        [\n            \"git\",\n            \"fetch\",\n            remote,\n            f\"refs/heads/{branch_name}:refs/heads/{branch_name}\",\n        ],\n        cwd=repo_path,\n    )\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.current_branch","title":"<code>current_branch(repo_path)</code>  <code>staticmethod</code>","text":"<p>Return the name of the current branch.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>@staticmethod\ndef current_branch(repo_path: Path | str) -&gt; str:\n    \"\"\"Return the name of the current branch.\"\"\"\n    result = _run_git([\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=repo_path)\n    return result.stdout.strip()\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.add_and_commit","title":"<code>add_and_commit(repo_path, message, *, paths=None)</code>  <code>staticmethod</code>","text":"<p>Stage files and commit. Returns the commit SHA.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>Path | str</code> <p>Local repo directory.</p> required <code>message</code> <code>str</code> <p>Commit message.</p> required <code>paths</code> <code>list[str] | None</code> <p>Specific paths to <code>git add</code>. Defaults to <code>[\".\"]</code> (all).</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The short SHA of the new commit.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>@staticmethod\ndef add_and_commit(\n    repo_path: Path | str,\n    message: str,\n    *,\n    paths: list[str] | None = None,\n) -&gt; str:\n    \"\"\"Stage files and commit. Returns the commit SHA.\n\n    Args:\n        repo_path: Local repo directory.\n        message: Commit message.\n        paths: Specific paths to ``git add``. Defaults to ``[\".\"]`` (all).\n\n    Returns:\n        The short SHA of the new commit.\n    \"\"\"\n    targets = paths or [\".\"]\n    _run_git([\"git\", \"add\", *targets], cwd=repo_path)\n    _run_git([\"git\", \"commit\", \"-m\", message], cwd=repo_path)\n    result = _run_git([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], cwd=repo_path)\n    return result.stdout.strip()\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.set_local_identity","title":"<code>set_local_identity(repo_path, *, name, email)</code>  <code>staticmethod</code>","text":"<p>Set git author identity in local repo config.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>@staticmethod\ndef set_local_identity(\n    repo_path: Path | str,\n    *,\n    name: str,\n    email: str,\n) -&gt; None:\n    \"\"\"Set git author identity in local repo config.\"\"\"\n    _run_git([\"git\", \"config\", \"user.name\", name], cwd=repo_path)\n    _run_git([\"git\", \"config\", \"user.email\", email], cwd=repo_path)\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.push","title":"<code>push(repo_path, *, remote='origin', branch=None, set_upstream=True)</code>","text":"<p>Push the current branch to the remote.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>Path | str</code> <p>Local repo directory.</p> required <code>remote</code> <code>str</code> <p>Remote name.</p> <code>'origin'</code> <code>branch</code> <code>str | None</code> <p>Branch to push. Defaults to current branch.</p> <code>None</code> <code>set_upstream</code> <code>bool</code> <p>If True, set the upstream tracking ref.</p> <code>True</code> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def push(\n    self,\n    repo_path: Path | str,\n    *,\n    remote: str = \"origin\",\n    branch: str | None = None,\n    set_upstream: bool = True,\n) -&gt; None:\n    \"\"\"Push the current branch to the remote.\n\n    Args:\n        repo_path: Local repo directory.\n        remote: Remote name.\n        branch: Branch to push. Defaults to current branch.\n        set_upstream: If True, set the upstream tracking ref.\n    \"\"\"\n    branch = branch or self.current_branch(repo_path)\n    cmd = [\"git\", \"push\"]\n    if set_upstream:\n        cmd += [\"-u\", remote, branch]\n    else:\n        cmd += [remote, branch]\n    _run_git(cmd, cwd=repo_path)\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.create_pr","title":"<code>create_pr(full_name, *, title, body='', head, base='main', draft=False)</code>","text":"<p>Create a pull request on GitHub.</p> <p>Parameters:</p> Name Type Description Default <code>full_name</code> <code>str</code> <p><code>owner/repo</code> string.</p> required <code>title</code> <code>str</code> <p>PR title.</p> required <code>body</code> <code>str</code> <p>PR body (markdown).</p> <code>''</code> <code>head</code> <code>str</code> <p>Source branch name.</p> required <code>base</code> <code>str</code> <p>Target branch name.</p> <code>'main'</code> <code>draft</code> <code>bool</code> <p>Whether to create as a draft PR.</p> <code>False</code> <p>Returns:</p> Type Description <code>PRResult</code> <p>A <code>PRResult</code> with the PR number, URL, title, head, and base.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def create_pr(\n    self,\n    full_name: str,\n    *,\n    title: str,\n    body: str = \"\",\n    head: str,\n    base: str = \"main\",\n    draft: bool = False,\n) -&gt; PRResult:\n    \"\"\"Create a pull request on GitHub.\n\n    Args:\n        full_name: ``owner/repo`` string.\n        title: PR title.\n        body: PR body (markdown).\n        head: Source branch name.\n        base: Target branch name.\n        draft: Whether to create as a draft PR.\n\n    Returns:\n        A ``PRResult`` with the PR number, URL, title, head, and base.\n    \"\"\"\n    repo = self.get_repo(full_name)\n    pr: PullRequest = repo.create_pull(\n        title=title, body=body, head=head, base=base, draft=draft\n    )\n    logger.info(\"Created PR #%d: %s\", pr.number, pr.html_url)\n    return PRResult(\n        number=pr.number,\n        url=pr.html_url,\n        title=pr.title,\n        head=head,\n        base=base,\n    )\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.list_prs","title":"<code>list_prs(full_name, *, state='open', limit=30)</code>","text":"<p>List pull requests for a repo.</p> <p>Parameters:</p> Name Type Description Default <code>full_name</code> <code>str</code> <p><code>owner/repo</code> string.</p> required <code>state</code> <code>str</code> <p><code>\"open\"</code>, <code>\"closed\"</code>, or <code>\"all\"</code>.</p> <code>'open'</code> <code>limit</code> <code>int</code> <p>Maximum number of PRs to return.</p> <code>30</code> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def list_prs(\n    self,\n    full_name: str,\n    *,\n    state: str = \"open\",\n    limit: int = 30,\n) -&gt; list[dict[str, Any]]:\n    \"\"\"List pull requests for a repo.\n\n    Args:\n        full_name: ``owner/repo`` string.\n        state: ``\"open\"``, ``\"closed\"``, or ``\"all\"``.\n        limit: Maximum number of PRs to return.\n    \"\"\"\n    repo = self.get_repo(full_name)\n    prs: list[PullRequest] = list(\n        repo.get_pulls(state=state, sort=\"created\", direction=\"desc\")\n    )[:limit]\n    return [\n        {\n            \"number\": pr.number,\n            \"title\": pr.title,\n            \"url\": pr.html_url,\n            \"state\": pr.state,\n            \"head\": pr.head.ref,\n            \"base\": pr.base.ref,\n        }\n        for pr in prs\n    ]\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.get_pr","title":"<code>get_pr(full_name, number)</code>","text":"<p>Get details of a single pull request.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def get_pr(self, full_name: str, number: int) -&gt; dict[str, Any]:\n    \"\"\"Get details of a single pull request.\"\"\"\n    repo = self.get_repo(full_name)\n    pr = repo.get_pull(number)\n    return {\n        \"number\": pr.number,\n        \"title\": pr.title,\n        \"body\": pr.body,\n        \"url\": pr.html_url,\n        \"state\": pr.state,\n        \"head\": pr.head.ref,\n        \"base\": pr.base.ref,\n        \"mergeable\": pr.mergeable,\n        \"merged\": pr.merged,\n    }\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.default_branch","title":"<code>default_branch(full_name)</code>","text":"<p>Return the repository's default branch.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def default_branch(self, full_name: str) -&gt; str:\n    \"\"\"Return the repository's default branch.\"\"\"\n    repo = self.get_repo(full_name)\n    return str(repo.default_branch)\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.update_pr_body","title":"<code>update_pr_body(full_name, number, *, body)</code>","text":"<p>Update the body/description of an existing pull request.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def update_pr_body(self, full_name: str, number: int, *, body: str) -&gt; None:\n    \"\"\"Update the body/description of an existing pull request.\"\"\"\n    repo = self.get_repo(full_name)\n    pr = repo.get_pull(number)\n    pr.edit(body=body)\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.upsert_pr_comment","title":"<code>upsert_pr_comment(full_name, number, *, body, marker='&lt;!-- helping_hands:status --&gt;')</code>","text":"<p>Create or update a marker-tagged PR comment.</p> <p>If a comment containing <code>marker</code> already exists, it is edited in place. Otherwise, a new comment is created.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def upsert_pr_comment(\n    self,\n    full_name: str,\n    number: int,\n    *,\n    body: str,\n    marker: str = \"&lt;!-- helping_hands:status --&gt;\",\n) -&gt; int:\n    \"\"\"Create or update a marker-tagged PR comment.\n\n    If a comment containing ``marker`` already exists, it is edited in place.\n    Otherwise, a new comment is created.\n    \"\"\"\n    repo = self.get_repo(full_name)\n    issue = repo.get_issue(number=number)\n    comment_body = body.rstrip()\n    if marker and marker not in comment_body:\n        comment_body = f\"{comment_body}\\n\\n{marker}\"\n\n    for comment in issue.get_comments():\n        existing = comment.body or \"\"\n        if marker and marker in existing:\n            comment.edit(comment_body)\n            return int(comment.id)\n\n    created = issue.create_comment(comment_body)\n    return int(created.id)\n</code></pre>"},{"location":"api/lib/github/#helping_hands.lib.github.GitHubClient.close","title":"<code>close()</code>","text":"<p>Close the underlying GitHub connection.</p> Source code in <code>src/helping_hands/lib/github.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the underlying GitHub connection.\"\"\"\n    self._gh.close()\n</code></pre>"},{"location":"api/lib/repo/","title":"repo","text":""},{"location":"api/lib/repo/#helping_hands.lib.repo","title":"<code>helping_hands.lib.repo</code>","text":"<p>Repository ingestion: clone, walk, and index a git repo.</p>"},{"location":"api/lib/repo/#helping_hands.lib.repo.RepoIndex","title":"<code>RepoIndex</code>  <code>dataclass</code>","text":"<p>Structural map of a repository.</p> Source code in <code>src/helping_hands/lib/repo.py</code> <pre><code>@dataclass\nclass RepoIndex:\n    \"\"\"Structural map of a repository.\"\"\"\n\n    root: Path\n    files: list[str] = field(default_factory=list)\n\n    @classmethod\n    def from_path(cls, path: Path) -&gt; RepoIndex:\n        \"\"\"Walk a local repo and build an index of its files.\"\"\"\n        if not path.is_dir():\n            msg = f\"Not a directory: {path}\"\n            raise FileNotFoundError(msg)\n\n        files = sorted(\n            str(p.relative_to(path))\n            for p in path.rglob(\"*\")\n            if p.is_file() and \".git\" not in p.parts\n        )\n        return cls(root=path, files=files)\n</code></pre>"},{"location":"api/lib/repo/#helping_hands.lib.repo.RepoIndex.from_path","title":"<code>from_path(path)</code>  <code>classmethod</code>","text":"<p>Walk a local repo and build an index of its files.</p> Source code in <code>src/helping_hands/lib/repo.py</code> <pre><code>@classmethod\ndef from_path(cls, path: Path) -&gt; RepoIndex:\n    \"\"\"Walk a local repo and build an index of its files.\"\"\"\n    if not path.is_dir():\n        msg = f\"Not a directory: {path}\"\n        raise FileNotFoundError(msg)\n\n    files = sorted(\n        str(p.relative_to(path))\n        for p in path.rglob(\"*\")\n        if p.is_file() and \".git\" not in p.parts\n    )\n    return cls(root=path, files=files)\n</code></pre>"},{"location":"api/lib/ai_providers/anthropic/","title":"lib.ai_providers.anthropic","text":""},{"location":"api/lib/ai_providers/anthropic/#helping_hands.lib.ai_providers.anthropic","title":"<code>helping_hands.lib.ai_providers.anthropic</code>","text":"<p>Anthropic provider wrapper.</p>"},{"location":"api/lib/ai_providers/anthropic/#helping_hands.lib.ai_providers.anthropic.AnthropicProvider","title":"<code>AnthropicProvider</code>","text":"<p>               Bases: <code>AIProvider</code></p> <p>Wrapper around the Anthropic Python SDK client.</p> Source code in <code>src/helping_hands/lib/ai_providers/anthropic.py</code> <pre><code>class AnthropicProvider(AIProvider):\n    \"\"\"Wrapper around the Anthropic Python SDK client.\"\"\"\n\n    name = \"anthropic\"\n    api_key_env_var = \"ANTHROPIC_API_KEY\"\n    default_model = \"claude-3-5-sonnet-latest\"\n    install_hint = \"uv add anthropic\"\n\n    def _build_inner(self) -&gt; Any:\n        try:\n            from anthropic import Anthropic\n        except ImportError as exc:\n            raise RuntimeError(\n                \"Anthropic SDK is not installed. Install with: uv add anthropic\"\n            ) from exc\n\n        api_key = os.environ.get(self.api_key_env_var)\n        if api_key:\n            return Anthropic(api_key=api_key)\n        return Anthropic()\n\n    def _complete_impl(\n        self,\n        *,\n        inner: Any,\n        messages: list[dict[str, str]],\n        model: str,\n        **kwargs: Any,\n    ) -&gt; Any:\n        max_tokens = kwargs.pop(\"max_tokens\", 1024)\n        return inner.messages.create(\n            model=model,\n            max_tokens=max_tokens,\n            messages=messages,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/lib/ai_providers/google/","title":"lib.ai_providers.google","text":""},{"location":"api/lib/ai_providers/google/#helping_hands.lib.ai_providers.google","title":"<code>helping_hands.lib.ai_providers.google</code>","text":"<p>Google provider wrapper.</p>"},{"location":"api/lib/ai_providers/google/#helping_hands.lib.ai_providers.google.GoogleProvider","title":"<code>GoogleProvider</code>","text":"<p>               Bases: <code>AIProvider</code></p> <p>Wrapper around the Google GenAI Python SDK client.</p> Source code in <code>src/helping_hands/lib/ai_providers/google.py</code> <pre><code>class GoogleProvider(AIProvider):\n    \"\"\"Wrapper around the Google GenAI Python SDK client.\"\"\"\n\n    name = \"google\"\n    api_key_env_var = \"GOOGLE_API_KEY\"\n    default_model = \"gemini-2.0-flash\"\n    install_hint = \"uv add google-genai\"\n\n    def _build_inner(self) -&gt; Any:\n        try:\n            from google import genai\n        except ImportError as exc:\n            raise RuntimeError(\n                \"Google GenAI SDK is not installed. Install with: uv add google-genai\"\n            ) from exc\n\n        api_key = os.environ.get(self.api_key_env_var)\n        if api_key:\n            return genai.Client(api_key=api_key)\n        return genai.Client()\n\n    def _complete_impl(\n        self,\n        *,\n        inner: Any,\n        messages: list[dict[str, str]],\n        model: str,\n        **kwargs: Any,\n    ) -&gt; Any:\n        contents = [m[\"content\"] for m in messages if m[\"content\"]]\n        return inner.models.generate_content(\n            model=model,\n            contents=contents,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/lib/ai_providers/litellm/","title":"lib.ai_providers.litellm","text":""},{"location":"api/lib/ai_providers/litellm/#helping_hands.lib.ai_providers.litellm","title":"<code>helping_hands.lib.ai_providers.litellm</code>","text":"<p>LiteLLM provider wrapper.</p>"},{"location":"api/lib/ai_providers/litellm/#helping_hands.lib.ai_providers.litellm.LiteLLMProvider","title":"<code>LiteLLMProvider</code>","text":"<p>               Bases: <code>AIProvider</code></p> <p>Wrapper around the LiteLLM Python package.</p> Source code in <code>src/helping_hands/lib/ai_providers/litellm.py</code> <pre><code>class LiteLLMProvider(AIProvider):\n    \"\"\"Wrapper around the LiteLLM Python package.\"\"\"\n\n    name = \"litellm\"\n    api_key_env_var = \"LITELLM_API_KEY\"\n    default_model = \"gpt-5.2\"\n    install_hint = \"uv add litellm\"\n\n    def _build_inner(self) -&gt; Any:\n        try:\n            import litellm\n        except ImportError as exc:\n            raise RuntimeError(\n                \"LiteLLM is not installed. Install with: uv add litellm\"\n            ) from exc\n\n        api_key = os.environ.get(self.api_key_env_var)\n        if api_key:\n            litellm.api_key = api_key\n        return litellm\n\n    def _complete_impl(\n        self,\n        *,\n        inner: Any,\n        messages: list[dict[str, str]],\n        model: str,\n        **kwargs: Any,\n    ) -&gt; Any:\n        return inner.completion(\n            model=model,\n            messages=messages,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/lib/ai_providers/openai/","title":"lib.ai_providers.openai","text":""},{"location":"api/lib/ai_providers/openai/#helping_hands.lib.ai_providers.openai","title":"<code>helping_hands.lib.ai_providers.openai</code>","text":"<p>OpenAI provider wrapper.</p>"},{"location":"api/lib/ai_providers/openai/#helping_hands.lib.ai_providers.openai.OpenAIProvider","title":"<code>OpenAIProvider</code>","text":"<p>               Bases: <code>AIProvider</code></p> <p>Wrapper around the OpenAI Python SDK client.</p> Source code in <code>src/helping_hands/lib/ai_providers/openai.py</code> <pre><code>class OpenAIProvider(AIProvider):\n    \"\"\"Wrapper around the OpenAI Python SDK client.\"\"\"\n\n    name = \"openai\"\n    api_key_env_var = \"OPENAI_API_KEY\"\n    default_model = \"gpt-5.2\"\n    install_hint = \"uv add openai\"\n\n    def _build_inner(self) -&gt; Any:\n        try:\n            from openai import OpenAI\n        except ImportError as exc:\n            raise RuntimeError(\n                \"OpenAI SDK is not installed. Install with: uv add openai\"\n            ) from exc\n\n        api_key = os.environ.get(self.api_key_env_var)\n        if api_key:\n            return OpenAI(api_key=api_key)\n        return OpenAI()\n\n    def _complete_impl(\n        self,\n        *,\n        inner: Any,\n        messages: list[dict[str, str]],\n        model: str,\n        **kwargs: Any,\n    ) -&gt; Any:\n        return inner.responses.create(\n            model=model,\n            input=messages,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/lib/ai_providers/types/","title":"lib.ai_providers.types","text":""},{"location":"api/lib/ai_providers/types/#helping_hands.lib.ai_providers.types","title":"<code>helping_hands.lib.ai_providers.types</code>","text":"<p>Shared provider wrapper interface and helpers.</p> <p>The classes in <code>helping_hands.lib.ai_providers</code> are thin wrappers around provider-specific SDK clients. They expose a common interface while still allowing backend-specific access via <code>provider.inner</code>.</p>"},{"location":"api/lib/ai_providers/types/#helping_hands.lib.ai_providers.types.AIProvider","title":"<code>AIProvider</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Common provider wrapper interface with lazy inner client loading.</p> Source code in <code>src/helping_hands/lib/ai_providers/types.py</code> <pre><code>class AIProvider(abc.ABC):\n    \"\"\"Common provider wrapper interface with lazy inner client loading.\"\"\"\n\n    name: str\n    api_key_env_var: str\n    default_model: str\n\n    def __init__(self, *, inner: Any | None = None) -&gt; None:\n        self._inner = inner\n\n    @property\n    def inner(self) -&gt; Any:\n        \"\"\"Provider-specific underlying SDK object.\"\"\"\n        if self._inner is None:\n            self._inner = self._build_inner()\n        return self._inner\n\n    @property\n    @abc.abstractmethod\n    def install_hint(self) -&gt; str:\n        \"\"\"Human-readable dependency install hint.\"\"\"\n\n    @abc.abstractmethod\n    def _build_inner(self) -&gt; Any:\n        \"\"\"Construct the provider-specific SDK client/module.\"\"\"\n\n    @abc.abstractmethod\n    def _complete_impl(\n        self,\n        *,\n        inner: Any,\n        messages: list[dict[str, str]],\n        model: str,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Provider-specific completion call implementation.\"\"\"\n\n    def complete(\n        self,\n        prompt_or_messages: PromptInput,\n        *,\n        model: str | None = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Run a completion call using the provider-specific implementation.\"\"\"\n        messages = normalize_messages(prompt_or_messages)\n        resolved_model = model or self.default_model\n        return self._complete_impl(\n            inner=self.inner,\n            messages=messages,\n            model=resolved_model,\n            **kwargs,\n        )\n\n    async def acomplete(\n        self,\n        prompt_or_messages: PromptInput,\n        *,\n        model: str | None = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Async completion wrapper around ``complete``.\"\"\"\n        return await asyncio.to_thread(\n            self.complete,\n            prompt_or_messages,\n            model=model,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/lib/ai_providers/types/#helping_hands.lib.ai_providers.types.AIProvider.inner","title":"<code>inner</code>  <code>property</code>","text":"<p>Provider-specific underlying SDK object.</p>"},{"location":"api/lib/ai_providers/types/#helping_hands.lib.ai_providers.types.AIProvider.install_hint","title":"<code>install_hint</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Human-readable dependency install hint.</p>"},{"location":"api/lib/ai_providers/types/#helping_hands.lib.ai_providers.types.AIProvider.complete","title":"<code>complete(prompt_or_messages, *, model=None, **kwargs)</code>","text":"<p>Run a completion call using the provider-specific implementation.</p> Source code in <code>src/helping_hands/lib/ai_providers/types.py</code> <pre><code>def complete(\n    self,\n    prompt_or_messages: PromptInput,\n    *,\n    model: str | None = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Run a completion call using the provider-specific implementation.\"\"\"\n    messages = normalize_messages(prompt_or_messages)\n    resolved_model = model or self.default_model\n    return self._complete_impl(\n        inner=self.inner,\n        messages=messages,\n        model=resolved_model,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/lib/ai_providers/types/#helping_hands.lib.ai_providers.types.AIProvider.acomplete","title":"<code>acomplete(prompt_or_messages, *, model=None, **kwargs)</code>  <code>async</code>","text":"<p>Async completion wrapper around <code>complete</code>.</p> Source code in <code>src/helping_hands/lib/ai_providers/types.py</code> <pre><code>async def acomplete(\n    self,\n    prompt_or_messages: PromptInput,\n    *,\n    model: str | None = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Async completion wrapper around ``complete``.\"\"\"\n    return await asyncio.to_thread(\n        self.complete,\n        prompt_or_messages,\n        model=model,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/lib/ai_providers/types/#helping_hands.lib.ai_providers.types.normalize_messages","title":"<code>normalize_messages(prompt_or_messages)</code>","text":"<p>Normalize caller input into chat-style <code>[{role, content}]</code> messages.</p> Source code in <code>src/helping_hands/lib/ai_providers/types.py</code> <pre><code>def normalize_messages(prompt_or_messages: PromptInput) -&gt; list[dict[str, str]]:\n    \"\"\"Normalize caller input into chat-style ``[{role, content}]`` messages.\"\"\"\n    if isinstance(prompt_or_messages, str):\n        return [{\"role\": \"user\", \"content\": prompt_or_messages}]\n\n    normalized: list[dict[str, str]] = []\n    for msg in prompt_or_messages:\n        role = str(msg.get(\"role\", \"user\"))\n        content = str(msg.get(\"content\", \"\"))\n        normalized.append({\"role\": role, \"content\": content})\n    return normalized\n</code></pre>"},{"location":"api/lib/hands/v1/hand/","title":"lib.hands.v1.hand (package)","text":""},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand","title":"<code>helping_hands.lib.hands.v1.hand</code>","text":"<p>Public import surface for hand backends in <code>helping_hands.lib.hands.v1</code>.</p> <p>This package-level module is the compatibility boundary consumed by: - <code>helping_hands.cli.main</code> for CLI backend routing. - <code>helping_hands.server.celery_app</code> for E2E task execution. - <code>helping_hands.lib.hands.v1</code> and external imports that use   <code>from helping_hands.lib.hands.v1.hand import ...</code>.</p> <p>It re-exports the abstract interface (<code>Hand</code>, <code>HandResponse</code>) plus all concrete backend classes from sibling modules. The <code>subprocess</code> alias is kept for backward-compatible patch targets in tests.</p>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.AtomicHand","title":"<code>AtomicHand</code>","text":"<p>               Bases: <code>Hand</code></p> <p>Hand backed by the atomic-agents framework.</p> <p>Requires the <code>atomic</code> extra to be installed.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/atomic.py</code> <pre><code>class AtomicHand(Hand):\n    \"\"\"Hand backed by the atomic-agents framework.\n\n    Requires the ``atomic`` extra to be installed.\n    \"\"\"\n\n    def __init__(self, config: Any, repo_index: Any) -&gt; None:\n        super().__init__(config, repo_index)\n        self._input_schema: type[Any] = None  # type: ignore[assignment]\n        self._hand_model = resolve_hand_model(self.config.model)\n        self._agent = self._build_agent()\n\n    def _build_agent(self) -&gt; Any:\n        from atomic_agents import AgentConfig, AtomicAgent, BasicChatInputSchema\n        from atomic_agents.context import (\n            ChatHistory,\n            SystemPromptGenerator,\n        )\n\n        self._input_schema = BasicChatInputSchema\n\n        client = build_atomic_client(self._hand_model)\n        history = ChatHistory()\n        prompt_gen = SystemPromptGenerator(\n            background=[self._build_system_prompt()],\n        )\n        return AtomicAgent(\n            config=AgentConfig(\n                client=client,\n                model=self._hand_model.model,\n                history=history,\n                system_prompt_generator=prompt_gen,\n            )\n        )\n\n    def _make_input(self, prompt: str) -&gt; Any:\n        \"\"\"Build an input schema instance. Uses mock-safe stored class.\"\"\"\n        return self._input_schema(chat_message=prompt)\n\n    def run(self, prompt: str) -&gt; HandResponse:\n        response = self._agent.run(self._make_input(prompt))\n        message = response.chat_message\n        pr_metadata = self._finalize_repo_pr(\n            backend=\"atomic\",\n            prompt=prompt,\n            summary=message,\n        )\n        return HandResponse(\n            message=message,\n            metadata={\n                \"backend\": \"atomic\",\n                \"model\": self._hand_model.model,\n                \"provider\": self._hand_model.provider.name,\n                **pr_metadata,\n            },\n        )\n\n    async def stream(self, prompt: str) -&gt; AsyncIterator[str]:\n        parts: list[str] = []\n        user_input = self._make_input(prompt)\n        try:\n            async_result = self._agent.run_async(user_input)\n        except AssertionError:\n            partial = await asyncio.to_thread(self._agent.run, user_input)\n            if hasattr(partial, \"chat_message\") and partial.chat_message:\n                text = str(partial.chat_message)\n                parts.append(text)\n                yield text\n            async_result = None\n        except Exception:\n            raise\n        if async_result is None:\n            pass\n        elif hasattr(async_result, \"__aiter__\"):\n            async for partial in async_result:\n                if hasattr(partial, \"chat_message\") and partial.chat_message:\n                    text = str(partial.chat_message)\n                    parts.append(text)\n                    yield text\n        else:\n            try:\n                partial = await async_result\n            except AssertionError:\n                partial = await asyncio.to_thread(self._agent.run, user_input)\n            if hasattr(partial, \"chat_message\") and partial.chat_message:\n                text = str(partial.chat_message)\n                parts.append(text)\n                yield text\n        pr_metadata = self._finalize_repo_pr(\n            backend=\"atomic\",\n            prompt=prompt,\n            summary=\"\".join(parts),\n        )\n        if pr_metadata.get(\"pr_url\"):\n            yield f\"\\nPR created: {pr_metadata['pr_url']}\\n\"\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.Hand","title":"<code>Hand</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base for all Hand backends.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/base.py</code> <pre><code>class Hand(abc.ABC):\n    \"\"\"Abstract base for all Hand backends.\"\"\"\n\n    def __init__(self, config: Config, repo_index: RepoIndex) -&gt; None:\n        self.config = config\n        self.repo_index = repo_index\n        self._interrupt_event = Event()\n        self.auto_pr = True\n\n    def _build_system_prompt(self) -&gt; str:\n        \"\"\"Build a system prompt that includes repo context.\"\"\"\n        file_list = \"\\n\".join(f\"  - {f}\" for f in self.repo_index.files[:200])\n        return (\n            \"You are a helpful coding assistant working on a repository.\\n\"\n            f\"Repo root: {self.repo_index.root}\\n\"\n            f\"Files ({len(self.repo_index.files)} total):\\n{file_list}\\n\\n\"\n            \"Follow the repo's conventions. Propose focused, reviewable \"\n            \"changes. Explain your reasoning.\"\n        )\n\n    @abc.abstractmethod\n    def run(self, prompt: str) -&gt; HandResponse:\n        \"\"\"Send a prompt and get a complete response.\"\"\"\n\n    @abc.abstractmethod\n    async def stream(self, prompt: str) -&gt; AsyncIterator[str]:\n        \"\"\"Send a prompt and yield response chunks as they arrive.\"\"\"\n\n    def interrupt(self) -&gt; None:\n        \"\"\"Request cooperative interruption for long-running runs/streams.\"\"\"\n        self._interrupt_event.set()\n\n    def reset_interrupt(self) -&gt; None:\n        \"\"\"Clear any pending interruption request.\"\"\"\n        self._interrupt_event.clear()\n\n    def _is_interrupted(self) -&gt; bool:\n        return self._interrupt_event.is_set()\n\n    @staticmethod\n    def _default_base_branch() -&gt; str:\n        return os.environ.get(\"HELPING_HANDS_BASE_BRANCH\", \"main\")\n\n    @staticmethod\n    def _run_git_read(repo_dir: Path, *args: str) -&gt; str:\n        result = subprocess.run(\n            [\"git\", *args],\n            cwd=repo_dir,\n            capture_output=True,\n            text=True,\n            check=False,\n        )\n        if result.returncode != 0:\n            return \"\"\n        return result.stdout.strip()\n\n    @classmethod\n    def _github_repo_from_origin(cls, repo_dir: Path) -&gt; str:\n        remote = cls._run_git_read(repo_dir, \"remote\", \"get-url\", \"origin\")\n        if not remote:\n            return \"\"\n        patterns = (\n            r\"^https://github\\.com/(?P&lt;repo&gt;[A-Za-z0-9_.-]+/[A-Za-z0-9_.-]+?)(?:\\.git)?$\",\n            r\"^git@github\\.com:(?P&lt;repo&gt;[A-Za-z0-9_.-]+/[A-Za-z0-9_.-]+?)(?:\\.git)?$\",\n            r\"^ssh://git@github\\.com/(?P&lt;repo&gt;[A-Za-z0-9_.-]+/[A-Za-z0-9_.-]+?)(?:\\.git)?$\",\n        )\n        for pattern in patterns:\n            match = re.match(pattern, remote)\n            if match:\n                return match.group(\"repo\")\n        return \"\"\n\n    @staticmethod\n    def _build_generic_pr_body(\n        *,\n        backend: str,\n        prompt: str,\n        summary: str,\n        commit_sha: str,\n        stamp_utc: str,\n    ) -&gt; str:\n        return (\n            f\"Automated update from `{backend}`.\\n\\n\"\n            f\"- latest_updated_utc: `{stamp_utc}`\\n\"\n            f\"- prompt: {prompt}\\n\"\n            f\"- commit: `{commit_sha}`\\n\\n\"\n            \"## Summary\\n\\n\"\n            f\"{summary.strip() or 'No summary provided.'}\\n\"\n        )\n\n    @staticmethod\n    def _configure_authenticated_push_remote(\n        repo_dir: Path, repo: str, token: str\n    ) -&gt; None:\n        push_url = f\"https://x-access-token:{token}@github.com/{repo}.git\"\n        result = subprocess.run(\n            [\"git\", \"remote\", \"set-url\", \"--push\", \"origin\", push_url],\n            cwd=repo_dir,\n            capture_output=True,\n            text=True,\n            check=False,\n        )\n        if result.returncode != 0:\n            stderr = result.stderr.strip() or \"unknown git error\"\n            msg = f\"failed to configure authenticated push remote: {stderr}\"\n            raise RuntimeError(msg)\n\n    def _finalize_repo_pr(\n        self,\n        *,\n        backend: str,\n        prompt: str,\n        summary: str,\n    ) -&gt; dict[str, str]:\n        metadata = {\n            \"auto_pr\": str(self.auto_pr).lower(),\n            \"pr_status\": \"not_attempted\",\n            \"pr_url\": \"\",\n            \"pr_number\": \"\",\n            \"pr_branch\": \"\",\n            \"pr_commit\": \"\",\n        }\n        if not self.auto_pr:\n            metadata[\"pr_status\"] = \"disabled\"\n            return metadata\n\n        repo_dir = self.repo_index.root.resolve()\n        if not repo_dir.is_dir():\n            metadata[\"pr_status\"] = \"no_repo\"\n            return metadata\n\n        inside_work_tree = self._run_git_read(\n            repo_dir, \"rev-parse\", \"--is-inside-work-tree\"\n        )\n        if inside_work_tree != \"true\":\n            metadata[\"pr_status\"] = \"not_git_repo\"\n            return metadata\n\n        has_changes = self._run_git_read(repo_dir, \"status\", \"--porcelain\")\n        if not has_changes:\n            metadata[\"pr_status\"] = \"no_changes\"\n            return metadata\n\n        repo = self._github_repo_from_origin(repo_dir)\n        if not repo:\n            metadata[\"pr_status\"] = \"no_github_origin\"\n            return metadata\n\n        from helping_hands.lib.github import GitHubClient\n\n        try:\n            with GitHubClient() as gh:\n                git_name = os.environ.get(\n                    \"HELPING_HANDS_GIT_USER_NAME\", \"helping-hands[bot]\"\n                )\n                git_email = os.environ.get(\n                    \"HELPING_HANDS_GIT_USER_EMAIL\",\n                    \"helping-hands-bot@users.noreply.github.com\",\n                )\n                gh.set_local_identity(repo_dir, name=git_name, email=git_email)\n\n                branch = f\"helping-hands/{backend}-{uuid4().hex[:8]}\"\n                gh.create_branch(repo_dir, branch)\n                commit_sha = gh.add_and_commit(\n                    repo_dir,\n                    f\"feat({backend}): apply hand updates\",\n                )\n                self._configure_authenticated_push_remote(repo_dir, repo, gh.token)\n                prior_prompt = os.environ.get(\"GIT_TERMINAL_PROMPT\")\n                prior_gcm_interactive = os.environ.get(\"GCM_INTERACTIVE\")\n                os.environ[\"GIT_TERMINAL_PROMPT\"] = \"0\"\n                os.environ[\"GCM_INTERACTIVE\"] = \"never\"\n                try:\n                    gh.push(repo_dir, branch=branch, set_upstream=True)\n                finally:\n                    if prior_prompt is None:\n                        os.environ.pop(\"GIT_TERMINAL_PROMPT\", None)\n                    else:\n                        os.environ[\"GIT_TERMINAL_PROMPT\"] = prior_prompt\n                    if prior_gcm_interactive is None:\n                        os.environ.pop(\"GCM_INTERACTIVE\", None)\n                    else:\n                        os.environ[\"GCM_INTERACTIVE\"] = prior_gcm_interactive\n\n                base_branch = self._default_base_branch()\n                try:\n                    repo_obj = gh.get_repo(repo)\n                    if getattr(repo_obj, \"default_branch\", \"\"):\n                        base_branch = str(repo_obj.default_branch)\n                except Exception:\n                    pass\n\n                stamp = datetime.now(UTC).replace(microsecond=0).isoformat()\n                pr = gh.create_pr(\n                    repo,\n                    title=f\"feat({backend}): automated hand update\",\n                    body=self._build_generic_pr_body(\n                        backend=backend,\n                        prompt=prompt,\n                        summary=summary,\n                        commit_sha=commit_sha,\n                        stamp_utc=stamp,\n                    ),\n                    head=branch,\n                    base=base_branch,\n                )\n                metadata.update(\n                    {\n                        \"pr_status\": \"created\",\n                        \"pr_url\": pr.url,\n                        \"pr_number\": str(pr.number),\n                        \"pr_branch\": branch,\n                        \"pr_commit\": commit_sha,\n                    }\n                )\n                return metadata\n        except ValueError as exc:\n            metadata[\"pr_status\"] = \"missing_token\"\n            metadata[\"pr_error\"] = str(exc)\n            return metadata\n        except RuntimeError as exc:\n            metadata[\"pr_status\"] = \"git_error\"\n            metadata[\"pr_error\"] = str(exc)\n            return metadata\n        except Exception as exc:\n            metadata[\"pr_status\"] = \"error\"\n            metadata[\"pr_error\"] = str(exc)\n            return metadata\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.Hand.run","title":"<code>run(prompt)</code>  <code>abstractmethod</code>","text":"<p>Send a prompt and get a complete response.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/base.py</code> <pre><code>@abc.abstractmethod\ndef run(self, prompt: str) -&gt; HandResponse:\n    \"\"\"Send a prompt and get a complete response.\"\"\"\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.Hand.stream","title":"<code>stream(prompt)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Send a prompt and yield response chunks as they arrive.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/base.py</code> <pre><code>@abc.abstractmethod\nasync def stream(self, prompt: str) -&gt; AsyncIterator[str]:\n    \"\"\"Send a prompt and yield response chunks as they arrive.\"\"\"\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.Hand.interrupt","title":"<code>interrupt()</code>","text":"<p>Request cooperative interruption for long-running runs/streams.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/base.py</code> <pre><code>def interrupt(self) -&gt; None:\n    \"\"\"Request cooperative interruption for long-running runs/streams.\"\"\"\n    self._interrupt_event.set()\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.Hand.reset_interrupt","title":"<code>reset_interrupt()</code>","text":"<p>Clear any pending interruption request.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/base.py</code> <pre><code>def reset_interrupt(self) -&gt; None:\n    \"\"\"Clear any pending interruption request.\"\"\"\n    self._interrupt_event.clear()\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.HandResponse","title":"<code>HandResponse</code>  <code>dataclass</code>","text":"<p>Standardised response from any Hand backend.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/base.py</code> <pre><code>@dataclass\nclass HandResponse:\n    \"\"\"Standardised response from any Hand backend.\"\"\"\n\n    message: str\n    metadata: dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.E2EHand","title":"<code>E2EHand</code>","text":"<p>               Bases: <code>Hand</code></p> <p>Minimal end-to-end hand for validating clone/edit/PR workflow.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/e2e.py</code> <pre><code>class E2EHand(Hand):\n    \"\"\"Minimal end-to-end hand for validating clone/edit/PR workflow.\"\"\"\n\n    def __init__(self, config: Any, repo_index: Any) -&gt; None:\n        super().__init__(config, repo_index)\n\n    @staticmethod\n    def _safe_repo_dir(repo: str) -&gt; str:\n        return re.sub(r\"[^A-Za-z0-9_.-]+\", \"_\", repo.strip(\"/\"))\n\n    @staticmethod\n    def _work_base() -&gt; Path:\n        root = os.environ.get(\"HELPING_HANDS_WORK_ROOT\", \".\")\n        return Path(root).expanduser()\n\n    @staticmethod\n    def _configured_base_branch() -&gt; str:\n        return os.environ.get(\"HELPING_HANDS_BASE_BRANCH\", \"\").strip()\n\n    @staticmethod\n    def _build_e2e_pr_comment(\n        *,\n        hand_uuid: str,\n        prompt: str,\n        stamp_utc: str,\n        commit_sha: str,\n    ) -&gt; str:\n        # E2E is deterministic; production hands should provide AI-authored\n        # PR summaries/comments when they own the PR workflow.\n        return (\n            \"## helping_hands E2E update\\n\\n\"\n            f\"- latest_updated_utc: `{stamp_utc}`\\n\"\n            f\"- hand_uuid: `{hand_uuid}`\\n\"\n            f\"- commit: `{commit_sha}`\\n\"\n            f\"- prompt: {prompt}\\n\"\n        )\n\n    @staticmethod\n    def _build_e2e_pr_body(\n        *,\n        hand_uuid: str,\n        prompt: str,\n        stamp_utc: str,\n        commit_sha: str,\n    ) -&gt; str:\n        return (\n            \"Automated E2E validation PR.\\n\\n\"\n            f\"- latest_updated_utc: `{stamp_utc}`\\n\"\n            f\"- hand_uuid: `{hand_uuid}`\\n\"\n            f\"- prompt: {prompt}\\n\"\n            f\"- commit: `{commit_sha}`\\n\"\n        )\n\n    def run(\n        self,\n        prompt: str,\n        hand_uuid: str | None = None,\n        pr_number: int | None = None,\n        dry_run: bool = False,\n    ) -&gt; HandResponse:\n        from helping_hands.lib.github import GitHubClient\n\n        repo = self.config.repo.strip()\n        if not repo:\n            raise ValueError(\"E2EHand requires config.repo set to a GitHub owner/repo.\")\n\n        hand_uuid = hand_uuid or str(uuid4())\n        safe_repo = self._safe_repo_dir(self.config.repo)\n        hand_root = self._work_base() / hand_uuid\n        repo_dir = hand_root / \"git\" / safe_repo\n        repo_dir.parent.mkdir(parents=True, exist_ok=True)\n\n        base_branch = self._configured_base_branch() or \"main\"\n        branch = f\"helping-hands/e2e-{hand_uuid[:8]}\"\n        e2e_file = \"HELPING_HANDS_E2E.md\"\n        e2e_path = repo_dir / e2e_file\n\n        with GitHubClient() as gh:\n            pr_url = \"\"\n            resumed_pr = False\n            pr_info: dict[str, Any] | None = None\n            clone_branch = base_branch\n            if pr_number is not None:\n                pr_info = gh.get_pr(repo, pr_number)\n                base_branch = str(pr_info[\"base\"])\n                pr_url = str(pr_info[\"url\"])\n                clone_branch = base_branch\n                if not dry_run:\n                    branch = str(pr_info[\"head\"])\n                    resumed_pr = True\n            elif not self._configured_base_branch():\n                try:\n                    base_branch = gh.default_branch(repo)\n                    clone_branch = base_branch\n                except Exception:\n                    clone_branch = None\n\n            gh.clone(repo, repo_dir, branch=clone_branch, depth=1)\n            if clone_branch is None:\n                detected = gh.current_branch(repo_dir)\n                if detected:\n                    base_branch = detected\n            repo_dir.mkdir(parents=True, exist_ok=True)\n            if resumed_pr:\n                gh.fetch_branch(repo_dir, branch)\n                gh.switch_branch(repo_dir, branch)\n            else:\n                gh.create_branch(repo_dir, branch)\n\n            stamp = datetime.now(UTC).replace(microsecond=0).isoformat()\n            e2e_path.write_text(\n                (\n                    \"# helping_hands E2E marker\\n\\n\"\n                    f\"- hand_uuid: `{hand_uuid}`\\n\"\n                    f\"- prompt: {prompt}\\n\"\n                    f\"- timestamp_utc: {stamp}\\n\"\n                ),\n                encoding=\"utf-8\",\n            )\n            commit_sha = \"\"\n            final_pr_number = pr_number\n            if not dry_run:\n                git_name = os.environ.get(\n                    \"HELPING_HANDS_GIT_USER_NAME\", \"helping-hands[bot]\"\n                )\n                git_email = os.environ.get(\n                    \"HELPING_HANDS_GIT_USER_EMAIL\",\n                    \"helping-hands-bot@users.noreply.github.com\",\n                )\n                gh.set_local_identity(repo_dir, name=git_name, email=git_email)\n                commit_sha = gh.add_and_commit(\n                    repo_dir,\n                    \"test(e2e): minimal change from E2EHand\",\n                    paths=[e2e_file],\n                )\n                gh.push(repo_dir, branch=branch, set_upstream=True)\n                pr_body = self._build_e2e_pr_body(\n                    hand_uuid=hand_uuid,\n                    prompt=prompt,\n                    stamp_utc=stamp,\n                    commit_sha=commit_sha,\n                )\n                if resumed_pr:\n                    final_pr_number = pr_number\n                else:\n                    pr = gh.create_pr(\n                        repo,\n                        title=\"test(e2e): minimal edit by helping_hands\",\n                        body=pr_body,\n                        head=branch,\n                        base=base_branch,\n                    )\n                    pr_url = pr.url\n                    final_pr_number = pr.number\n                if final_pr_number is not None:\n                    gh.update_pr_body(repo, final_pr_number, body=pr_body)\n                    gh.upsert_pr_comment(\n                        repo,\n                        final_pr_number,\n                        body=self._build_e2e_pr_comment(\n                            hand_uuid=hand_uuid,\n                            prompt=prompt,\n                            stamp_utc=stamp,\n                            commit_sha=commit_sha,\n                        ),\n                        marker=\"&lt;!-- helping_hands:e2e-status --&gt;\",\n                    )\n\n        if dry_run:\n            message = \"E2EHand dry run complete. No push/PR performed.\"\n        else:\n            message = f\"E2EHand complete. PR: {pr_url}\"\n        return HandResponse(\n            message=message,\n            metadata={\n                \"backend\": \"e2e\",\n                \"model\": self.config.model,\n                \"hand_uuid\": hand_uuid,\n                \"hand_root\": str(hand_root),\n                \"repo\": repo,\n                \"workspace\": str(repo_dir),\n                \"branch\": branch,\n                \"base_branch\": base_branch,\n                \"commit\": commit_sha,\n                \"pr_number\": \"\" if final_pr_number is None else str(final_pr_number),\n                \"pr_url\": pr_url,\n                \"resumed_pr\": str(resumed_pr).lower(),\n                \"dry_run\": str(dry_run).lower(),\n            },\n        )\n\n    async def stream(self, prompt: str) -&gt; AsyncIterator[str]:\n        yield self.run(prompt).message\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.BasicAtomicHand","title":"<code>BasicAtomicHand</code>","text":"<p>               Bases: <code>_BasicIterativeHand</code></p> <p>Iterative Atomic-backed hand with streaming and interruption.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/iterative.py</code> <pre><code>class BasicAtomicHand(_BasicIterativeHand):\n    \"\"\"Iterative Atomic-backed hand with streaming and interruption.\"\"\"\n\n    def __init__(\n        self,\n        config: Any,\n        repo_index: Any,\n        *,\n        max_iterations: int = 6,\n    ) -&gt; None:\n        super().__init__(config, repo_index, max_iterations=max_iterations)\n        self._input_schema: type[Any] = None  # type: ignore[assignment]\n        self._hand_model = resolve_hand_model(self.config.model)\n        self._agent = self._build_agent()\n\n    def _build_agent(self) -&gt; Any:\n        from atomic_agents import AgentConfig, AtomicAgent, BasicChatInputSchema\n        from atomic_agents.context import (\n            ChatHistory,\n            SystemPromptGenerator,\n        )\n\n        self._input_schema = BasicChatInputSchema\n\n        client = build_atomic_client(self._hand_model)\n        history = ChatHistory()\n        prompt_gen = SystemPromptGenerator(\n            background=[\n                self._build_system_prompt()\n                + \"\\n\\nYou are running an iterative repository implementation loop.\"\n                \" Keep responses concise, implementation-focused, and deterministic.\"\n            ],\n        )\n        return AtomicAgent(\n            config=AgentConfig(\n                client=client,\n                model=self._hand_model.model,\n                history=history,\n                system_prompt_generator=prompt_gen,\n            )\n        )\n\n    def _make_input(self, prompt: str) -&gt; Any:\n        return self._input_schema(chat_message=prompt)\n\n    @staticmethod\n    def _extract_message(response: Any) -&gt; str:\n        if hasattr(response, \"chat_message\") and response.chat_message:\n            return str(response.chat_message)\n        return str(response)\n\n    def run(self, prompt: str) -&gt; HandResponse:\n        self.reset_interrupt()\n        prior = \"\"\n        bootstrap_context = self._build_bootstrap_context()\n        transcripts: list[str] = []\n        completed = False\n        iterations = 0\n\n        for iteration in range(1, self.max_iterations + 1):\n            if self._is_interrupted():\n                break\n            iterations = iteration\n            step_prompt = self._build_iteration_prompt(\n                prompt=prompt,\n                iteration=iteration,\n                max_iterations=self.max_iterations,\n                previous_summary=prior,\n                bootstrap_context=bootstrap_context if iteration == 1 else \"\",\n            )\n            response = self._agent.run(self._make_input(step_prompt))\n            content = self._extract_message(response)\n            changed = self._apply_inline_edits(content)\n            read_feedback = self._execute_read_requests(content)\n            transcripts.append(f\"[iteration {iteration}]\\n{content}\")\n            if changed:\n                transcripts.append(f\"[files updated] {', '.join(changed)}\")\n            if read_feedback:\n                transcripts.append(f\"[tool results]\\n{read_feedback}\")\n            prior = self._merge_iteration_summary(content, read_feedback)\n            if self._is_satisfied(content):\n                completed = True\n                break\n\n        interrupted = self._is_interrupted()\n        if interrupted:\n            status = \"interrupted\"\n        elif completed:\n            status = \"satisfied\"\n        else:\n            status = \"max_iterations\"\n\n        pr_metadata = self._finalize_repo_pr(\n            backend=\"basic-atomic\",\n            prompt=prompt,\n            summary=prior,\n        )\n        message = \"\\n\\n\".join(transcripts) if transcripts else \"No output produced.\"\n        return HandResponse(\n            message=message,\n            metadata={\n                \"backend\": \"basic-atomic\",\n                \"model\": self._hand_model.model,\n                \"provider\": self._hand_model.provider.name,\n                \"iterations\": iterations,\n                \"status\": status,\n                \"interrupted\": str(interrupted).lower(),\n                **pr_metadata,\n            },\n        )\n\n    async def stream(self, prompt: str) -&gt; AsyncIterator[str]:\n        self.reset_interrupt()\n        prior = \"\"\n        bootstrap_context = self._build_bootstrap_context()\n\n        for iteration in range(1, self.max_iterations + 1):\n            if self._is_interrupted():\n                yield \"\\n[interrupted]\\n\"\n                return\n\n            yield f\"\\n[iteration {iteration}/{self.max_iterations}]\\n\"\n            step_prompt = self._build_iteration_prompt(\n                prompt=prompt,\n                iteration=iteration,\n                max_iterations=self.max_iterations,\n                previous_summary=prior,\n                bootstrap_context=bootstrap_context if iteration == 1 else \"\",\n            )\n            stream_text = \"\"\n            step_input = self._make_input(step_prompt)\n            try:\n                async_result = self._agent.run_async(step_input)\n            except AssertionError:\n                partial = await asyncio.to_thread(self._agent.run, step_input)\n                current = self._extract_message(partial)\n                if current.startswith(stream_text):\n                    delta = current[len(stream_text) :]\n                else:\n                    delta = current\n                stream_text = current\n                if delta:\n                    yield delta\n                async_result = None\n            except Exception:\n                raise\n            if async_result is not None and hasattr(async_result, \"__aiter__\"):\n                async for partial in async_result:\n                    if self._is_interrupted():\n                        break\n                    current = self._extract_message(partial)\n                    if current.startswith(stream_text):\n                        delta = current[len(stream_text) :]\n                    else:\n                        delta = current\n                    stream_text = current\n                    if delta:\n                        yield delta\n            elif async_result is not None:\n                try:\n                    partial = await async_result\n                except AssertionError:\n                    partial = await asyncio.to_thread(self._agent.run, step_input)\n                current = self._extract_message(partial)\n                if current.startswith(stream_text):\n                    delta = current[len(stream_text) :]\n                else:\n                    delta = current\n                stream_text = current\n                if delta:\n                    yield delta\n            if self._is_interrupted():\n                yield \"\\n[interrupted]\\n\"\n                return\n\n            changed = self._apply_inline_edits(stream_text)\n            if changed:\n                yield f\"\\n[files updated] {', '.join(changed)}\\n\"\n            read_feedback = self._execute_read_requests(stream_text)\n            if read_feedback:\n                yield f\"\\n[tool results]\\n{read_feedback}\\n\"\n            prior = self._merge_iteration_summary(stream_text, read_feedback)\n            if self._is_satisfied(stream_text):\n                yield \"\\n\\nTask marked satisfied.\\n\"\n                pr_metadata = self._finalize_repo_pr(\n                    backend=\"basic-atomic\",\n                    prompt=prompt,\n                    summary=stream_text,\n                )\n                if pr_metadata.get(\"pr_url\"):\n                    yield f\"\\nPR created: {pr_metadata['pr_url']}\\n\"\n                elif pr_metadata.get(\"pr_status\") not in {\"no_changes\", \"disabled\"}:\n                    yield f\"\\nPR status: {pr_metadata.get('pr_status')}\\n\"\n                return\n            yield \"\\n\\nContinuing...\\n\"\n\n        pr_metadata = self._finalize_repo_pr(\n            backend=\"basic-atomic\",\n            prompt=prompt,\n            summary=prior,\n        )\n        if pr_metadata.get(\"pr_url\"):\n            yield f\"\\nPR created: {pr_metadata['pr_url']}\\n\"\n        elif pr_metadata.get(\"pr_status\") not in {\"no_changes\", \"disabled\"}:\n            yield f\"\\nPR status: {pr_metadata.get('pr_status')}\\n\"\n        yield \"\\n\\nMax iterations reached.\\n\"\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.BasicLangGraphHand","title":"<code>BasicLangGraphHand</code>","text":"<p>               Bases: <code>_BasicIterativeHand</code></p> <p>Iterative LangGraph-backed hand with streaming and interruption.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/iterative.py</code> <pre><code>class BasicLangGraphHand(_BasicIterativeHand):\n    \"\"\"Iterative LangGraph-backed hand with streaming and interruption.\"\"\"\n\n    def __init__(\n        self,\n        config: Any,\n        repo_index: Any,\n        *,\n        max_iterations: int = 6,\n    ) -&gt; None:\n        super().__init__(config, repo_index, max_iterations=max_iterations)\n        self._hand_model = resolve_hand_model(self.config.model)\n        self._agent = self._build_agent()\n\n    def _build_agent(self) -&gt; Any:\n        from langgraph.prebuilt import create_react_agent\n\n        llm = build_langchain_chat_model(\n            self._hand_model,\n            streaming=True,\n        )\n        system_prompt = (\n            self._build_system_prompt()\n            + \"\\n\\nYou are running an iterative repository implementation loop.\"\n            \" Keep responses concise, implementation-focused, and deterministic.\"\n        )\n        return create_react_agent(\n            model=llm,\n            tools=[],\n            prompt=system_prompt,\n        )\n\n    @staticmethod\n    def _result_content(result: dict[str, Any]) -&gt; str:\n        messages = result.get(\"messages\") or []\n        if not messages:\n            return \"\"\n        last_msg = messages[-1]\n        return last_msg.content if hasattr(last_msg, \"content\") else str(last_msg)\n\n    def run(self, prompt: str) -&gt; HandResponse:\n        self.reset_interrupt()\n        prior = \"\"\n        bootstrap_context = self._build_bootstrap_context()\n        transcripts: list[str] = []\n        completed = False\n        iterations = 0\n\n        for iteration in range(1, self.max_iterations + 1):\n            if self._is_interrupted():\n                break\n            iterations = iteration\n            step_prompt = self._build_iteration_prompt(\n                prompt=prompt,\n                iteration=iteration,\n                max_iterations=self.max_iterations,\n                previous_summary=prior,\n                bootstrap_context=bootstrap_context if iteration == 1 else \"\",\n            )\n            result = self._agent.invoke(\n                {\"messages\": [{\"role\": \"user\", \"content\": step_prompt}]}\n            )\n            content = self._result_content(result)\n            changed = self._apply_inline_edits(content)\n            read_feedback = self._execute_read_requests(content)\n            transcripts.append(f\"[iteration {iteration}]\\n{content}\")\n            if changed:\n                transcripts.append(f\"[files updated] {', '.join(changed)}\")\n            if read_feedback:\n                transcripts.append(f\"[tool results]\\n{read_feedback}\")\n            prior = self._merge_iteration_summary(content, read_feedback)\n            if self._is_satisfied(content):\n                completed = True\n                break\n\n        interrupted = self._is_interrupted()\n        if interrupted:\n            status = \"interrupted\"\n        elif completed:\n            status = \"satisfied\"\n        else:\n            status = \"max_iterations\"\n\n        pr_metadata = self._finalize_repo_pr(\n            backend=\"basic-langgraph\",\n            prompt=prompt,\n            summary=prior,\n        )\n        message = \"\\n\\n\".join(transcripts) if transcripts else \"No output produced.\"\n        return HandResponse(\n            message=message,\n            metadata={\n                \"backend\": \"basic-langgraph\",\n                \"model\": self._hand_model.model,\n                \"provider\": self._hand_model.provider.name,\n                \"iterations\": iterations,\n                \"status\": status,\n                \"interrupted\": str(interrupted).lower(),\n                **pr_metadata,\n            },\n        )\n\n    async def stream(self, prompt: str) -&gt; AsyncIterator[str]:\n        self.reset_interrupt()\n        prior = \"\"\n        bootstrap_context = self._build_bootstrap_context()\n\n        for iteration in range(1, self.max_iterations + 1):\n            if self._is_interrupted():\n                yield \"\\n[interrupted]\\n\"\n                return\n\n            yield f\"\\n[iteration {iteration}/{self.max_iterations}]\\n\"\n            step_prompt = self._build_iteration_prompt(\n                prompt=prompt,\n                iteration=iteration,\n                max_iterations=self.max_iterations,\n                previous_summary=prior,\n                bootstrap_context=bootstrap_context if iteration == 1 else \"\",\n            )\n            parts: list[str] = []\n            async for event in self._agent.astream_events(\n                {\"messages\": [{\"role\": \"user\", \"content\": step_prompt}]},\n                version=\"v2\",\n            ):\n                if self._is_interrupted():\n                    break\n                if event[\"event\"] == \"on_chat_model_stream\" and event[\"data\"].get(\n                    \"chunk\"\n                ):\n                    chunk = event[\"data\"][\"chunk\"]\n                    text = chunk.content if hasattr(chunk, \"content\") else \"\"\n                    if text:\n                        parts.append(str(text))\n                        yield str(text)\n            if self._is_interrupted():\n                yield \"\\n[interrupted]\\n\"\n                return\n\n            content = \"\".join(parts)\n            changed = self._apply_inline_edits(content)\n            if changed:\n                yield f\"\\n[files updated] {', '.join(changed)}\\n\"\n            read_feedback = self._execute_read_requests(content)\n            if read_feedback:\n                yield f\"\\n[tool results]\\n{read_feedback}\\n\"\n            prior = self._merge_iteration_summary(content, read_feedback)\n            if self._is_satisfied(content):\n                yield \"\\n\\nTask marked satisfied.\\n\"\n                pr_metadata = self._finalize_repo_pr(\n                    backend=\"basic-langgraph\",\n                    prompt=prompt,\n                    summary=content,\n                )\n                if pr_metadata.get(\"pr_url\"):\n                    yield f\"\\nPR created: {pr_metadata['pr_url']}\\n\"\n                elif pr_metadata.get(\"pr_status\") not in {\"no_changes\", \"disabled\"}:\n                    yield f\"\\nPR status: {pr_metadata.get('pr_status')}\\n\"\n                return\n            yield \"\\n\\nContinuing...\\n\"\n\n        pr_metadata = self._finalize_repo_pr(\n            backend=\"basic-langgraph\",\n            prompt=prompt,\n            summary=prior,\n        )\n        if pr_metadata.get(\"pr_url\"):\n            yield f\"\\nPR created: {pr_metadata['pr_url']}\\n\"\n        elif pr_metadata.get(\"pr_status\") not in {\"no_changes\", \"disabled\"}:\n            yield f\"\\nPR status: {pr_metadata.get('pr_status')}\\n\"\n        yield \"\\n\\nMax iterations reached.\\n\"\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.LangGraphHand","title":"<code>LangGraphHand</code>","text":"<p>               Bases: <code>Hand</code></p> <p>Hand backed by LangChain / LangGraph <code>create_react_agent</code>.</p> <p>Requires the <code>langchain</code> extra to be installed.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/langgraph.py</code> <pre><code>class LangGraphHand(Hand):\n    \"\"\"Hand backed by LangChain / LangGraph ``create_react_agent``.\n\n    Requires the ``langchain`` extra to be installed.\n    \"\"\"\n\n    def __init__(self, config: Any, repo_index: Any) -&gt; None:\n        super().__init__(config, repo_index)\n        self._hand_model = resolve_hand_model(self.config.model)\n        self._agent = self._build_agent()\n\n    def _build_agent(self) -&gt; Any:\n        from langgraph.prebuilt import create_react_agent\n\n        llm = build_langchain_chat_model(\n            self._hand_model,\n            streaming=True,\n        )\n        system_prompt = self._build_system_prompt()\n        return create_react_agent(\n            model=llm,\n            tools=[],\n            prompt=system_prompt,\n        )\n\n    def run(self, prompt: str) -&gt; HandResponse:\n        result = self._agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n        last_msg = result[\"messages\"][-1]\n        content = last_msg.content if hasattr(last_msg, \"content\") else str(last_msg)\n        pr_metadata = self._finalize_repo_pr(\n            backend=\"langgraph\",\n            prompt=prompt,\n            summary=content,\n        )\n        return HandResponse(\n            message=content,\n            metadata={\n                \"backend\": \"langgraph\",\n                \"model\": self._hand_model.model,\n                \"provider\": self._hand_model.provider.name,\n                **pr_metadata,\n            },\n        )\n\n    async def stream(self, prompt: str) -&gt; AsyncIterator[str]:\n        parts: list[str] = []\n        async for event in self._agent.astream_events(\n            {\"messages\": [{\"role\": \"user\", \"content\": prompt}]},\n            version=\"v2\",\n        ):\n            if event[\"event\"] == \"on_chat_model_stream\" and event[\"data\"].get(\"chunk\"):\n                chunk = event[\"data\"][\"chunk\"]\n                if hasattr(chunk, \"content\") and chunk.content:\n                    text = str(chunk.content)\n                    parts.append(text)\n                    yield text\n        pr_metadata = self._finalize_repo_pr(\n            backend=\"langgraph\",\n            prompt=prompt,\n            summary=\"\".join(parts),\n        )\n        if pr_metadata.get(\"pr_url\"):\n            yield f\"\\nPR created: {pr_metadata['pr_url']}\\n\"\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.ClaudeCodeHand","title":"<code>ClaudeCodeHand</code>","text":"<p>               Bases: <code>Hand</code></p> <p>Hand backed by Claude Code via a terminal/bash invocation.</p> <p>This backend would run the Claude Code CLI (or equivalent) as a subprocess: e.g. a terminal/bash call that passes the repo path and user prompt, then captures stdout/stderr. Not yet implemented; this class is scaffolding for future integration.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/placeholders.py</code> <pre><code>class ClaudeCodeHand(Hand):\n    \"\"\"Hand backed by Claude Code via a terminal/bash invocation.\n\n    This backend would run the Claude Code CLI (or equivalent) as a\n    subprocess: e.g. a terminal/bash call that passes the repo path and\n    user prompt, then captures stdout/stderr. Not yet implemented; this\n    class is scaffolding for future integration.\n    \"\"\"\n\n    def __init__(self, config: Any, repo_index: Any) -&gt; None:\n        super().__init__(config, repo_index)\n\n    def run(self, prompt: str) -&gt; HandResponse:\n        pr_metadata = self._finalize_repo_pr(\n            backend=\"claudecode\",\n            prompt=prompt,\n            summary=\"ClaudeCode hand not yet implemented.\",\n        )\n        return HandResponse(\n            message=\"ClaudeCode hand not yet implemented.\",\n            metadata={\n                \"backend\": \"claudecode\",\n                \"model\": self.config.model,\n                **pr_metadata,\n            },\n        )\n\n    async def stream(self, prompt: str) -&gt; AsyncIterator[str]:\n        yield \"ClaudeCode hand not yet implemented.\"\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.CodexCLIHand","title":"<code>CodexCLIHand</code>","text":"<p>               Bases: <code>Hand</code></p> <p>Hand backed by Codex CLI subprocess execution.</p> <p>The hand runs two phases: 1. initialize/learn repository context (README/AGENT/tree conventions), 2. execute the user task with that learned summary.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/placeholders.py</code> <pre><code>class CodexCLIHand(Hand):\n    \"\"\"Hand backed by Codex CLI subprocess execution.\n\n    The hand runs two phases:\n    1. initialize/learn repository context (README/AGENT/tree conventions),\n    2. execute the user task with that learned summary.\n    \"\"\"\n\n    _DEFAULT_CLI_CMD = \"codex exec\"\n    _DEFAULT_CODEX_MODEL = \"gpt-5.2\"\n    _DEFAULT_SANDBOX_MODE = \"workspace-write\"\n    _DEFAULT_SANDBOX_MODE_IN_CONTAINER = \"danger-full-access\"\n    _DEFAULT_SKIP_GIT_REPO_CHECK = \"1\"\n    _SUMMARY_CHAR_LIMIT = 6000\n\n    def __init__(self, config: Any, repo_index: Any) -&gt; None:\n        super().__init__(config, repo_index)\n        self._active_process: asyncio.subprocess.Process | None = None\n\n    class _Emitter(Protocol):\n        async def __call__(self, chunk: str) -&gt; None: ...\n\n    @staticmethod\n    def _truncate_summary(text: str, *, limit: int) -&gt; str:\n        clean = text.strip()\n        if len(clean) &lt;= limit:\n            return clean\n        return f\"{clean[:limit]}\\n...[truncated]\"\n\n    @staticmethod\n    def _build_codex_failure_message(*, return_code: int, output: str) -&gt; str:\n        tail = output.strip()[-2000:]\n        lower_tail = tail.lower()\n        if (\n            \"401 unauthorized\" in lower_tail\n            or \"missing bearer or basic authentication\" in lower_tail\n        ):\n            return (\n                \"Codex CLI authentication failed (401 Unauthorized). \"\n                \"Ensure OPENAI_API_KEY is set in this runtime. \"\n                \"If running app mode in Docker, set OPENAI_API_KEY in .env \"\n                \"and recreate server/worker containers.\\n\"\n                f\"Output:\\n{tail}\"\n            )\n        return f\"Codex CLI failed (exit={return_code}). Output:\\n{tail}\"\n\n    def _base_command(self) -&gt; list[str]:\n        raw = os.environ.get(\"HELPING_HANDS_CODEX_CLI_CMD\", self._DEFAULT_CLI_CMD)\n        tokens = shlex.split(raw)\n        if not tokens:\n            msg = \"HELPING_HANDS_CODEX_CLI_CMD resolved to an empty command.\"\n            raise RuntimeError(msg)\n\n        # ``codex`` with no subcommand opens interactive mode; ensure non-interactive.\n        if tokens[0] == \"codex\" and len(tokens) == 1:\n            tokens.append(\"exec\")\n        return tokens\n\n    def _resolve_codex_model(self) -&gt; str:\n        model = str(self.config.model).strip()\n        if not model or model == \"default\":\n            return self._DEFAULT_CODEX_MODEL\n        if \"/\" in model:\n            _, _, provider_model = model.partition(\"/\")\n            if provider_model:\n                return provider_model\n        return model\n\n    def _render_command(self, prompt: str) -&gt; list[str]:\n        resolved_model = self._resolve_codex_model()\n        placeholders = {\n            \"{prompt}\": prompt,\n            \"{repo}\": str(self.repo_index.root.resolve()),\n            \"{model}\": resolved_model,\n        }\n        rendered: list[str] = []\n        has_prompt_placeholder = False\n        used_model_placeholder = False\n        for token in self._base_command():\n            updated = token\n            for key, value in placeholders.items():\n                if key in updated:\n                    updated = updated.replace(key, value)\n                    if key == \"{prompt}\":\n                        has_prompt_placeholder = True\n                    if key == \"{model}\":\n                        used_model_placeholder = True\n            rendered.append(updated)\n\n        has_explicit_model_flag = any(\n            token == \"--model\" or token.startswith(\"--model=\") for token in rendered\n        )\n        if not used_model_placeholder and not has_explicit_model_flag:\n            rendered.extend([\"--model\", resolved_model])\n\n        if not has_prompt_placeholder:\n            rendered.append(prompt)\n        rendered = self._apply_codex_exec_sandbox_defaults(rendered)\n        rendered = self._apply_codex_exec_git_repo_check_defaults(rendered)\n        return self._wrap_container_if_enabled(rendered)\n\n    @staticmethod\n    def _is_truthy(value: str | None) -&gt; bool:\n        if value is None:\n            return False\n        return value.strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}\n\n    def _container_enabled(self) -&gt; bool:\n        raw = os.environ.get(\"HELPING_HANDS_CODEX_CONTAINER\", \"\")\n        if raw == \"\":\n            return False\n        return self._is_truthy(raw)\n\n    def _container_image(self) -&gt; str:\n        image = os.environ.get(\"HELPING_HANDS_CODEX_CONTAINER_IMAGE\", \"\").strip()\n        if not image:\n            msg = (\n                \"HELPING_HANDS_CODEX_CONTAINER_IMAGE must be set when \"\n                \"HELPING_HANDS_CODEX_CONTAINER is enabled.\"\n            )\n            raise RuntimeError(msg)\n        return image\n\n    def _apply_codex_exec_sandbox_defaults(self, cmd: list[str]) -&gt; list[str]:\n        if len(cmd) &lt; 2 or cmd[0] != \"codex\" or cmd[1] != \"exec\":\n            return cmd\n        if any(token == \"--sandbox\" or token.startswith(\"--sandbox=\") for token in cmd):\n            return cmd\n        sandbox_mode = os.environ.get(\"HELPING_HANDS_CODEX_SANDBOX_MODE\")\n        if sandbox_mode is None:\n            sandbox_mode = self._auto_sandbox_mode()\n        else:\n            sandbox_mode = sandbox_mode.strip() or self._auto_sandbox_mode()\n        if not sandbox_mode:\n            sandbox_mode = self._auto_sandbox_mode()\n        return [*cmd[:2], \"--sandbox\", sandbox_mode, *cmd[2:]]\n\n    def _auto_sandbox_mode(self) -&gt; str:\n        if Path(\"/.dockerenv\").exists():\n            return self._DEFAULT_SANDBOX_MODE_IN_CONTAINER\n        return self._DEFAULT_SANDBOX_MODE\n\n    def _skip_git_repo_check_enabled(self) -&gt; bool:\n        raw = os.environ.get(\n            \"HELPING_HANDS_CODEX_SKIP_GIT_REPO_CHECK\",\n            self._DEFAULT_SKIP_GIT_REPO_CHECK,\n        )\n        return self._is_truthy(raw)\n\n    def _apply_codex_exec_git_repo_check_defaults(self, cmd: list[str]) -&gt; list[str]:\n        if len(cmd) &lt; 2 or cmd[0] != \"codex\" or cmd[1] != \"exec\":\n            return cmd\n        if any(\n            token == \"--skip-git-repo-check\"\n            or token.startswith(\"--skip-git-repo-check\")\n            for token in cmd\n        ):\n            return cmd\n        if not self._skip_git_repo_check_enabled():\n            return cmd\n        return [*cmd[:2], \"--skip-git-repo-check\", *cmd[2:]]\n\n    def _wrap_container_if_enabled(self, cmd: list[str]) -&gt; list[str]:\n        if not self._container_enabled():\n            return cmd\n        image = self._container_image()\n        if shutil.which(\"docker\") is None:\n            msg = (\n                \"HELPING_HANDS_CODEX_CONTAINER is enabled but docker is not \"\n                \"available on PATH.\"\n            )\n            raise RuntimeError(msg)\n        repo_root = str(self.repo_index.root.resolve())\n        docker_cmd = [\n            \"docker\",\n            \"run\",\n            \"--rm\",\n            \"-i\",\n            \"-v\",\n            f\"{repo_root}:/workspace\",\n            \"-w\",\n            \"/workspace\",\n        ]\n        for env_name in (\n            \"OPENAI_API_KEY\",\n            \"ANTHROPIC_API_KEY\",\n            \"GEMINI_API_KEY\",\n            \"HELPING_HANDS_MODEL\",\n        ):\n            value = os.environ.get(env_name)\n            if value:\n                docker_cmd.extend([\"-e\", f\"{env_name}={value}\"])\n        docker_cmd.append(image)\n        docker_cmd.extend(cmd)\n        return docker_cmd\n\n    def _execution_mode(self) -&gt; str:\n        if self._container_enabled():\n            return \"container+workspace-write\"\n        return \"workspace-write\"\n\n    def _build_init_prompt(self) -&gt; str:\n        file_list = \"\\n\".join(f\"- {path}\" for path in self.repo_index.files[:200])\n        if not file_list:\n            file_list = \"- (no indexed files)\"\n        return (\n            \"Initialization phase: learn this repository before task execution.\\n\"\n            f\"Repository root: {self.repo_index.root}\\n\"\n            \"Goals:\\n\"\n            \"1. Read README.md and AGENT.md if they exist.\\n\"\n            \"2. Learn conventions from the file tree snapshot.\\n\"\n            \"3. Output a concise implementation-oriented summary.\\n\"\n            \"Do not ask the user for file contents.\\n\"\n            \"Do not perform edits in this phase.\\n\\n\"\n            \"Indexed files:\\n\"\n            f\"{file_list}\\n\"\n        )\n\n    def _build_task_prompt(self, *, prompt: str, learned_summary: str) -&gt; str:\n        summary = self._truncate_summary(\n            learned_summary,\n            limit=self._SUMMARY_CHAR_LIMIT,\n        )\n        return (\n            \"Task execution phase.\\n\\n\"\n            \"Repository context learned from initialization:\\n\"\n            f\"{summary or '(no summary produced)'}\\n\\n\"\n            \"User task request:\\n\"\n            f\"{prompt}\\n\\n\"\n            \"Implement the task directly in the repository. \"\n            \"Do not ask the user to paste files.\"\n        )\n\n    async def _terminate_active_process(self) -&gt; None:\n        process = self._active_process\n        if process is None or process.returncode is not None:\n            return\n        process.terminate()\n        try:\n            await asyncio.wait_for(process.wait(), timeout=5)\n        except TimeoutError:\n            process.kill()\n            await process.wait()\n\n    async def _invoke_codex(\n        self,\n        prompt: str,\n        *,\n        emit: _Emitter,\n    ) -&gt; str:\n        cmd = self._render_command(prompt)\n        # Pass env explicitly so Codex CLI sees OPENAI_API_KEY etc. (Celery worker\n        # may not pass env to child on some setups).\n        env = dict(os.environ)\n        try:\n            process = await asyncio.create_subprocess_exec(\n                *cmd,\n                cwd=str(self.repo_index.root.resolve()),\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.STDOUT,\n                env=env,\n            )\n        except FileNotFoundError as exc:\n            msg = (\n                f\"Codex CLI command not found: {cmd[0]!r}. \"\n                \"Set HELPING_HANDS_CODEX_CLI_CMD to a valid command. \"\n                \"If running app mode in Docker, rebuild worker images so \"\n                \"the codex binary is installed.\"\n            )\n            raise RuntimeError(msg) from exc\n\n        self._active_process = process\n        chunks: list[str] = []\n        stdout = process.stdout\n        if stdout is None:\n            await process.wait()\n            self._active_process = None\n            msg = \"Codex CLI did not expose stdout pipe.\"\n            raise RuntimeError(msg)\n\n        try:\n            while True:\n                if self._is_interrupted():\n                    await self._terminate_active_process()\n                    break\n\n                data = await stdout.read(1024)\n                if not data:\n                    break\n\n                text = data.decode(\"utf-8\", errors=\"replace\")\n                chunks.append(text)\n                await emit(text)\n\n            if not self._is_interrupted():\n                return_code = await process.wait()\n                if return_code != 0:\n                    msg = self._build_codex_failure_message(\n                        return_code=return_code,\n                        output=\"\".join(chunks),\n                    )\n                    raise RuntimeError(msg)\n            return \"\".join(chunks)\n        finally:\n            self._active_process = None\n\n    async def _run_two_phase(\n        self,\n        prompt: str,\n        *,\n        emit: _Emitter,\n    ) -&gt; str:\n        self.reset_interrupt()\n        await emit(f\"[codexcli] isolation={self._execution_mode()}\\n\")\n        await emit(\"[codexcli] [phase 1/2] Initializing repository context...\\n\")\n        init_output = await self._invoke_codex(self._build_init_prompt(), emit=emit)\n        if self._is_interrupted():\n            await emit(\"[codexcli] Interrupted during initialization.\\n\")\n            return init_output\n\n        await emit(\"[codexcli] [phase 2/2] Executing user task...\\n\")\n        task_output = await self._invoke_codex(\n            self._build_task_prompt(prompt=prompt, learned_summary=init_output),\n            emit=emit,\n        )\n        return f\"{init_output}{task_output}\"\n\n    async def _collect_run_output(self, prompt: str) -&gt; str:\n        chunks: list[str] = []\n\n        async def _emit(chunk: str) -&gt; None:\n            chunks.append(chunk)\n\n        await self._run_two_phase(prompt, emit=_emit)\n        return \"\".join(chunks)\n\n    def _interrupted_pr_metadata(self) -&gt; dict[str, str]:\n        return {\n            \"auto_pr\": str(self.auto_pr).lower(),\n            \"pr_status\": \"interrupted\",\n            \"pr_url\": \"\",\n            \"pr_number\": \"\",\n            \"pr_branch\": \"\",\n            \"pr_commit\": \"\",\n        }\n\n    def _finalize_after_run(self, *, prompt: str, message: str) -&gt; dict[str, str]:\n        if self._is_interrupted():\n            return self._interrupted_pr_metadata()\n\n        summary = self._truncate_summary(message, limit=self._SUMMARY_CHAR_LIMIT)\n        return self._finalize_repo_pr(\n            backend=\"codexcli\",\n            prompt=prompt,\n            summary=summary,\n        )\n\n    @staticmethod\n    def _format_pr_status_message(metadata: dict[str, str]) -&gt; str | None:\n        status = metadata.get(\"pr_status\", \"\")\n        if not status:\n            return None\n        if status == \"created\":\n            pr_url = metadata.get(\"pr_url\", \"\")\n            return f\"[codexcli] PR created: {pr_url}\"\n        if status == \"disabled\":\n            return \"[codexcli] PR disabled (--no-pr).\"\n        if status == \"no_changes\":\n            return \"[codexcli] PR skipped: no file changes detected.\"\n        if status == \"interrupted\":\n            return \"[codexcli] Interrupted.\"\n        error = metadata.get(\"pr_error\", \"\").strip()\n        if error:\n            return f\"[codexcli] PR status: {status} ({error})\"\n        return f\"[codexcli] PR status: {status}\"\n\n    def interrupt(self) -&gt; None:\n        super().interrupt()\n        process = self._active_process\n        if process is not None and process.returncode is None:\n            process.terminate()\n\n    def run(self, prompt: str) -&gt; HandResponse:\n        message = asyncio.run(self._collect_run_output(prompt))\n        pr_metadata = self._finalize_after_run(prompt=prompt, message=message)\n        return HandResponse(\n            message=message,\n            metadata={\n                \"backend\": \"codexcli\",\n                \"model\": self.config.model,\n                **pr_metadata,\n            },\n        )\n\n    async def stream(self, prompt: str) -&gt; AsyncIterator[str]:\n        output_queue: asyncio.Queue[str | None] = asyncio.Queue()\n        collected: list[str] = []\n\n        async def _emit(chunk: str) -&gt; None:\n            collected.append(chunk)\n            await output_queue.put(chunk)\n\n        async def _produce() -&gt; None:\n            error: Exception | None = None\n            try:\n                await self._run_two_phase(prompt, emit=_emit)\n            except Exception as exc:  # pragma: no cover - propagated below\n                error = exc\n            finally:\n                if error is None:\n                    message = \"\".join(collected)\n                    metadata = self._finalize_after_run(prompt=prompt, message=message)\n                    pr_status_message = self._format_pr_status_message(metadata)\n                    if pr_status_message:\n                        await output_queue.put(f\"\\n{pr_status_message}\\n\")\n                await output_queue.put(None)\n            if error is not None:\n                raise error\n\n        producer_task = asyncio.create_task(_produce())\n        try:\n            while True:\n                chunk = await output_queue.get()\n                if chunk is None:\n                    break\n                yield chunk\n        finally:\n            if not producer_task.done():\n                producer_task.cancel()\n                with suppress(asyncio.CancelledError):\n                    await producer_task\n            else:\n                exc = producer_task.exception()\n                if exc is not None:\n                    raise exc  # pragma: no cover\n</code></pre>"},{"location":"api/lib/hands/v1/hand/#helping_hands.lib.hands.v1.hand.GeminiCLIHand","title":"<code>GeminiCLIHand</code>","text":"<p>               Bases: <code>Hand</code></p> <p>Hand backed by Gemini CLI via a terminal/bash invocation.</p> <p>This backend would run the Gemini CLI as a subprocess with repo context and the user prompt, then capture stdout/stderr. Not yet implemented; this class is scaffolding for future integration.</p> Source code in <code>src/helping_hands/lib/hands/v1/hand/placeholders.py</code> <pre><code>class GeminiCLIHand(Hand):\n    \"\"\"Hand backed by Gemini CLI via a terminal/bash invocation.\n\n    This backend would run the Gemini CLI as a subprocess with repo context\n    and the user prompt, then capture stdout/stderr. Not yet implemented;\n    this class is scaffolding for future integration.\n    \"\"\"\n\n    def __init__(self, config: Any, repo_index: Any) -&gt; None:\n        super().__init__(config, repo_index)\n\n    def run(self, prompt: str) -&gt; HandResponse:\n        pr_metadata = self._finalize_repo_pr(\n            backend=\"geminicli\",\n            prompt=prompt,\n            summary=\"GeminiCLI hand not yet implemented.\",\n        )\n        return HandResponse(\n            message=\"GeminiCLI hand not yet implemented.\",\n            metadata={\n                \"backend\": \"geminicli\",\n                \"model\": self.config.model,\n                **pr_metadata,\n            },\n        )\n\n    async def stream(self, prompt: str) -&gt; AsyncIterator[str]:\n        yield \"GeminiCLI hand not yet implemented.\"\n</code></pre>"},{"location":"api/lib/meta/tools/","title":"lib.meta.tools (package)","text":""},{"location":"api/lib/meta/tools/#helping_hands.lib.meta.tools","title":"<code>helping_hands.lib.meta.tools</code>","text":"<p>System tools package shared by hands and MCP.</p> <p>This package contains reusable system-facing helpers. The primary module is <code>filesystem</code>, which implements path-confined repo file operations used by iterative hands and exposed through MCP tools.</p>"},{"location":"api/lib/meta/tools/#helping_hands.lib.meta.tools.mkdir_path","title":"<code>mkdir_path(repo_root, rel_path)</code>","text":"<p>Create a repo-relative directory and return normalized path.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def mkdir_path(repo_root: Path, rel_path: str) -&gt; str:\n    \"\"\"Create a repo-relative directory and return normalized path.\"\"\"\n    root = repo_root.resolve()\n    target = resolve_repo_target(root, rel_path)\n    target.mkdir(parents=True, exist_ok=True)\n    return target.relative_to(root).as_posix()\n</code></pre>"},{"location":"api/lib/meta/tools/#helping_hands.lib.meta.tools.normalize_relative_path","title":"<code>normalize_relative_path(rel_path)</code>","text":"<p>Normalize a repo-relative path to a safe forward-slash form.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def normalize_relative_path(rel_path: str) -&gt; str:\n    \"\"\"Normalize a repo-relative path to a safe forward-slash form.\"\"\"\n    normalized = rel_path.strip().replace(\"\\\\\", \"/\")\n    if normalized.startswith(\"./\"):\n        normalized = normalized[2:]\n    return normalized\n</code></pre>"},{"location":"api/lib/meta/tools/#helping_hands.lib.meta.tools.path_exists","title":"<code>path_exists(repo_root, rel_path)</code>","text":"<p>Return whether a repo-relative path exists.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def path_exists(repo_root: Path, rel_path: str) -&gt; bool:\n    \"\"\"Return whether a repo-relative path exists.\"\"\"\n    try:\n        target = resolve_repo_target(repo_root, rel_path)\n    except ValueError:\n        return False\n    return target.exists()\n</code></pre>"},{"location":"api/lib/meta/tools/#helping_hands.lib.meta.tools.read_text_file","title":"<code>read_text_file(repo_root, rel_path, *, max_chars=None)</code>","text":"<p>Read a text file and return <code>(content, truncated, display_path)</code>.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def read_text_file(\n    repo_root: Path,\n    rel_path: str,\n    *,\n    max_chars: int | None = None,\n) -&gt; tuple[str, bool, str]:\n    \"\"\"Read a text file and return ``(content, truncated, display_path)``.\"\"\"\n    root = repo_root.resolve()\n    target = resolve_repo_target(root, rel_path)\n\n    if not target.exists():\n        raise FileNotFoundError(\"file not found\")\n    if target.is_dir():\n        raise IsADirectoryError(\"path is a directory\")\n\n    try:\n        text = target.read_text(encoding=\"utf-8\")\n    except UnicodeDecodeError as exc:\n        raise UnicodeError(\"file is not UTF-8 text\") from exc\n\n    truncated = False\n    if max_chars is not None and len(text) &gt; max_chars:\n        text = text[:max_chars]\n        truncated = True\n\n    display_path = target.relative_to(root).as_posix()\n    return text, truncated, display_path\n</code></pre>"},{"location":"api/lib/meta/tools/#helping_hands.lib.meta.tools.resolve_repo_target","title":"<code>resolve_repo_target(repo_root, rel_path)</code>","text":"<p>Resolve a relative path inside <code>repo_root</code> or raise <code>ValueError</code>.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def resolve_repo_target(repo_root: Path, rel_path: str) -&gt; Path:\n    \"\"\"Resolve a relative path inside ``repo_root`` or raise ``ValueError``.\"\"\"\n    root = repo_root.resolve()\n    normalized = normalize_relative_path(rel_path)\n    if not normalized or normalized.startswith(\"/\"):\n        raise ValueError(\"invalid path\")\n\n    target = (root / normalized).resolve()\n    try:\n        target.relative_to(root)\n    except ValueError as exc:\n        raise ValueError(\"invalid path\") from exc\n    return target\n</code></pre>"},{"location":"api/lib/meta/tools/#helping_hands.lib.meta.tools.write_text_file","title":"<code>write_text_file(repo_root, rel_path, content)</code>","text":"<p>Write UTF-8 text to a repo-relative file and return normalized path.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def write_text_file(repo_root: Path, rel_path: str, content: str) -&gt; str:\n    \"\"\"Write UTF-8 text to a repo-relative file and return normalized path.\"\"\"\n    root = repo_root.resolve()\n    target = resolve_repo_target(root, rel_path)\n    target.parent.mkdir(parents=True, exist_ok=True)\n    target.write_text(content, encoding=\"utf-8\")\n    return target.relative_to(root).as_posix()\n</code></pre>"},{"location":"api/lib/meta/tools/filesystem/","title":"lib.meta.tools.filesystem","text":""},{"location":"api/lib/meta/tools/filesystem/#helping_hands.lib.meta.tools.filesystem","title":"<code>helping_hands.lib.meta.tools.filesystem</code>","text":"<p>Filesystem tools for repo-aware execution.</p> <p>These helpers provide a narrow, reusable interface for safe path handling and file operations inside a repository root. They are consumed by hand modules and MCP tools so read/write behavior is centralized and path-confined.</p>"},{"location":"api/lib/meta/tools/filesystem/#helping_hands.lib.meta.tools.filesystem.normalize_relative_path","title":"<code>normalize_relative_path(rel_path)</code>","text":"<p>Normalize a repo-relative path to a safe forward-slash form.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def normalize_relative_path(rel_path: str) -&gt; str:\n    \"\"\"Normalize a repo-relative path to a safe forward-slash form.\"\"\"\n    normalized = rel_path.strip().replace(\"\\\\\", \"/\")\n    if normalized.startswith(\"./\"):\n        normalized = normalized[2:]\n    return normalized\n</code></pre>"},{"location":"api/lib/meta/tools/filesystem/#helping_hands.lib.meta.tools.filesystem.resolve_repo_target","title":"<code>resolve_repo_target(repo_root, rel_path)</code>","text":"<p>Resolve a relative path inside <code>repo_root</code> or raise <code>ValueError</code>.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def resolve_repo_target(repo_root: Path, rel_path: str) -&gt; Path:\n    \"\"\"Resolve a relative path inside ``repo_root`` or raise ``ValueError``.\"\"\"\n    root = repo_root.resolve()\n    normalized = normalize_relative_path(rel_path)\n    if not normalized or normalized.startswith(\"/\"):\n        raise ValueError(\"invalid path\")\n\n    target = (root / normalized).resolve()\n    try:\n        target.relative_to(root)\n    except ValueError as exc:\n        raise ValueError(\"invalid path\") from exc\n    return target\n</code></pre>"},{"location":"api/lib/meta/tools/filesystem/#helping_hands.lib.meta.tools.filesystem.read_text_file","title":"<code>read_text_file(repo_root, rel_path, *, max_chars=None)</code>","text":"<p>Read a text file and return <code>(content, truncated, display_path)</code>.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def read_text_file(\n    repo_root: Path,\n    rel_path: str,\n    *,\n    max_chars: int | None = None,\n) -&gt; tuple[str, bool, str]:\n    \"\"\"Read a text file and return ``(content, truncated, display_path)``.\"\"\"\n    root = repo_root.resolve()\n    target = resolve_repo_target(root, rel_path)\n\n    if not target.exists():\n        raise FileNotFoundError(\"file not found\")\n    if target.is_dir():\n        raise IsADirectoryError(\"path is a directory\")\n\n    try:\n        text = target.read_text(encoding=\"utf-8\")\n    except UnicodeDecodeError as exc:\n        raise UnicodeError(\"file is not UTF-8 text\") from exc\n\n    truncated = False\n    if max_chars is not None and len(text) &gt; max_chars:\n        text = text[:max_chars]\n        truncated = True\n\n    display_path = target.relative_to(root).as_posix()\n    return text, truncated, display_path\n</code></pre>"},{"location":"api/lib/meta/tools/filesystem/#helping_hands.lib.meta.tools.filesystem.write_text_file","title":"<code>write_text_file(repo_root, rel_path, content)</code>","text":"<p>Write UTF-8 text to a repo-relative file and return normalized path.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def write_text_file(repo_root: Path, rel_path: str, content: str) -&gt; str:\n    \"\"\"Write UTF-8 text to a repo-relative file and return normalized path.\"\"\"\n    root = repo_root.resolve()\n    target = resolve_repo_target(root, rel_path)\n    target.parent.mkdir(parents=True, exist_ok=True)\n    target.write_text(content, encoding=\"utf-8\")\n    return target.relative_to(root).as_posix()\n</code></pre>"},{"location":"api/lib/meta/tools/filesystem/#helping_hands.lib.meta.tools.filesystem.mkdir_path","title":"<code>mkdir_path(repo_root, rel_path)</code>","text":"<p>Create a repo-relative directory and return normalized path.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def mkdir_path(repo_root: Path, rel_path: str) -&gt; str:\n    \"\"\"Create a repo-relative directory and return normalized path.\"\"\"\n    root = repo_root.resolve()\n    target = resolve_repo_target(root, rel_path)\n    target.mkdir(parents=True, exist_ok=True)\n    return target.relative_to(root).as_posix()\n</code></pre>"},{"location":"api/lib/meta/tools/filesystem/#helping_hands.lib.meta.tools.filesystem.path_exists","title":"<code>path_exists(repo_root, rel_path)</code>","text":"<p>Return whether a repo-relative path exists.</p> Source code in <code>src/helping_hands/lib/meta/tools/filesystem.py</code> <pre><code>def path_exists(repo_root: Path, rel_path: str) -&gt; bool:\n    \"\"\"Return whether a repo-relative path exists.\"\"\"\n    try:\n        target = resolve_repo_target(repo_root, rel_path)\n    except ValueError:\n        return False\n    return target.exists()\n</code></pre>"},{"location":"api/server/app/","title":"server.app","text":""},{"location":"api/server/app/#helping_hands.server.app","title":"<code>helping_hands.server.app</code>","text":"<p>FastAPI application for app mode.</p> <p>Exposes an HTTP API that enqueues repo-building jobs via Celery.</p>"},{"location":"api/server/app/#helping_hands.server.app.BuildRequest","title":"<code>BuildRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request body for the /build endpoint.</p> Source code in <code>src/helping_hands/server/app.py</code> <pre><code>class BuildRequest(BaseModel):\n    \"\"\"Request body for the /build endpoint.\"\"\"\n\n    repo_path: str\n    prompt: str\n    backend: Literal[\n        \"e2e\",\n        \"basic-langgraph\",\n        \"basic-atomic\",\n        \"basic-agent\",\n        \"codexcli\",\n    ] = \"e2e\"\n    model: str | None = None\n    max_iterations: int = 6\n    no_pr: bool = False\n    pr_number: int | None = None\n</code></pre>"},{"location":"api/server/app/#helping_hands.server.app.BuildResponse","title":"<code>BuildResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response for an enqueued build job.</p> Source code in <code>src/helping_hands/server/app.py</code> <pre><code>class BuildResponse(BaseModel):\n    \"\"\"Response for an enqueued build job.\"\"\"\n\n    task_id: str\n    status: str\n    backend: str\n</code></pre>"},{"location":"api/server/app/#helping_hands.server.app.TaskStatus","title":"<code>TaskStatus</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response for checking task status.</p> Source code in <code>src/helping_hands/server/app.py</code> <pre><code>class TaskStatus(BaseModel):\n    \"\"\"Response for checking task status.\"\"\"\n\n    task_id: str\n    status: str\n    result: dict[str, Any] | None = None\n</code></pre>"},{"location":"api/server/app/#helping_hands.server.app.home","title":"<code>home()</code>","text":"<p>Simple browser UI to submit and monitor build runs.</p> Source code in <code>src/helping_hands/server/app.py</code> <pre><code>@app.get(\"/\", response_class=HTMLResponse)\ndef home() -&gt; HTMLResponse:\n    \"\"\"Simple browser UI to submit and monitor build runs.\"\"\"\n    return HTMLResponse(_UI_HTML)\n</code></pre>"},{"location":"api/server/app/#helping_hands.server.app.health","title":"<code>health()</code>","text":"<p>Health check.</p> Source code in <code>src/helping_hands/server/app.py</code> <pre><code>@app.get(\"/health\")\ndef health() -&gt; dict[str, str]:\n    \"\"\"Health check.\"\"\"\n    return {\"status\": \"ok\"}\n</code></pre>"},{"location":"api/server/app/#helping_hands.server.app.enqueue_build","title":"<code>enqueue_build(req)</code>","text":"<p>Enqueue a hand task and return the task ID.</p> <p>Supports E2E and iterative backends (<code>basic-langgraph</code>, <code>basic-atomic</code>, <code>basic-agent</code>) plus <code>codexcli</code>, using the same backend options as CLI.</p> Source code in <code>src/helping_hands/server/app.py</code> <pre><code>@app.post(\"/build\", response_model=BuildResponse)\ndef enqueue_build(req: BuildRequest) -&gt; BuildResponse:\n    \"\"\"Enqueue a hand task and return the task ID.\n\n    Supports E2E and iterative backends (`basic-langgraph`, `basic-atomic`,\n    `basic-agent`) plus `codexcli`, using the same backend options as CLI.\n    \"\"\"\n    return _enqueue_build_task(req)\n</code></pre>"},{"location":"api/server/app/#helping_hands.server.app.enqueue_build_form","title":"<code>enqueue_build_form(repo_path=Form(...), prompt=Form(...), backend=Form('e2e'), model=Form(None), max_iterations=Form(6), no_pr=Form(False), pr_number=Form(None))</code>","text":"<p>Fallback form endpoint so UI submits still enqueue without JS.</p> Source code in <code>src/helping_hands/server/app.py</code> <pre><code>@app.post(\"/build/form\")\ndef enqueue_build_form(\n    repo_path: str = Form(...),\n    prompt: str = Form(...),\n    backend: str = Form(\"e2e\"),\n    model: str | None = Form(None),\n    max_iterations: int = Form(6),\n    no_pr: bool = Form(False),\n    pr_number: int | None = Form(None),\n) -&gt; RedirectResponse:\n    \"\"\"Fallback form endpoint so UI submits still enqueue without JS.\"\"\"\n    try:\n        validated_backend = _parse_backend(backend)\n    except ValueError as exc:\n        query: dict[str, str] = {\n            \"repo_path\": repo_path,\n            \"prompt\": prompt,\n            \"backend\": backend,\n            \"max_iterations\": str(max_iterations),\n            \"error\": str(exc),\n        }\n        if model:\n            query[\"model\"] = model\n        if no_pr:\n            query[\"no_pr\"] = \"1\"\n        if pr_number is not None:\n            query[\"pr_number\"] = str(pr_number)\n        return RedirectResponse(url=f\"/?{urlencode(query)}\", status_code=303)\n\n    try:\n        req = BuildRequest(\n            repo_path=repo_path,\n            prompt=prompt,\n            backend=validated_backend,\n            model=model,\n            max_iterations=max_iterations,\n            no_pr=no_pr,\n            pr_number=pr_number,\n        )\n    except ValidationError as exc:\n        error_msg = \"Invalid form submission.\"\n        errors = exc.errors()\n        if errors:\n            first_error = errors[0]\n            if isinstance(first_error, dict):\n                maybe_msg = first_error.get(\"msg\")\n                if isinstance(maybe_msg, str):\n                    error_msg = maybe_msg\n\n        query: dict[str, str] = {\n            \"repo_path\": repo_path,\n            \"prompt\": prompt,\n            \"backend\": backend,\n            \"max_iterations\": str(max_iterations),\n            \"error\": error_msg,\n        }\n        if model:\n            query[\"model\"] = model\n        if no_pr:\n            query[\"no_pr\"] = \"1\"\n        if pr_number is not None:\n            query[\"pr_number\"] = str(pr_number)\n        return RedirectResponse(url=f\"/?{urlencode(query)}\", status_code=303)\n\n    response = _enqueue_build_task(req)\n    query = {\n        \"repo_path\": req.repo_path,\n        \"prompt\": req.prompt,\n        \"backend\": req.backend,\n        \"max_iterations\": str(req.max_iterations),\n        \"task_id\": response.task_id,\n        \"status\": response.status,\n    }\n    if req.model:\n        query[\"model\"] = req.model\n    if req.no_pr:\n        query[\"no_pr\"] = \"1\"\n    if req.pr_number is not None:\n        query[\"pr_number\"] = str(req.pr_number)\n    return RedirectResponse(url=f\"/monitor/{response.task_id}\", status_code=303)\n</code></pre>"},{"location":"api/server/app/#helping_hands.server.app.monitor","title":"<code>monitor(task_id)</code>","text":"<p>No-JS monitor page with auto-refresh for task status/updates.</p> Source code in <code>src/helping_hands/server/app.py</code> <pre><code>@app.get(\"/monitor/{task_id}\", response_class=HTMLResponse)\ndef monitor(task_id: str) -&gt; HTMLResponse:\n    \"\"\"No-JS monitor page with auto-refresh for task status/updates.\"\"\"\n    task_status = _build_task_status(task_id)\n    return HTMLResponse(_render_monitor_page(task_status))\n</code></pre>"},{"location":"api/server/app/#helping_hands.server.app.get_task","title":"<code>get_task(task_id)</code>","text":"<p>Check the status of an enqueued task.</p> Source code in <code>src/helping_hands/server/app.py</code> <pre><code>@app.get(\"/tasks/{task_id}\", response_model=TaskStatus)\ndef get_task(task_id: str) -&gt; TaskStatus:\n    \"\"\"Check the status of an enqueued task.\"\"\"\n    return _build_task_status(task_id)\n</code></pre>"},{"location":"api/server/celery_app/","title":"server.celery_app","text":""},{"location":"api/server/celery_app/#helping_hands.server.celery_app","title":"<code>helping_hands.server.celery_app</code>","text":"<p>Celery application and task definitions.</p>"},{"location":"api/server/celery_app/#helping_hands.server.celery_app.build_feature","title":"<code>build_feature(self, repo_path, prompt, pr_number=None, backend='e2e', model=None, max_iterations=6, no_pr=False)</code>","text":"<p>Async task: run a hand against a GitHub repo with a user prompt.</p> <p>This is the primary unit of work in app mode. The server enqueues this task; a worker picks it up, runs the hand, and stores the result. The Celery task ID is used as the hand UUID.</p> Source code in <code>src/helping_hands/server/celery_app.py</code> <pre><code>@celery_app.task(bind=True, name=\"helping_hands.build_feature\")\ndef build_feature(\n    self: object,\n    repo_path: str,\n    prompt: str,\n    pr_number: int | None = None,\n    backend: str = \"e2e\",\n    model: str | None = None,\n    max_iterations: int = 6,\n    no_pr: bool = False,\n) -&gt; dict[str, Any]:  # pragma: no cover - exercised in integration\n    \"\"\"Async task: run a hand against a GitHub repo with a user prompt.\n\n    This is the primary unit of work in app mode. The server enqueues this\n    task; a worker picks it up, runs the hand, and stores the result.\n    The Celery task ID is used as the hand UUID.\n    \"\"\"\n    from helping_hands.lib.config import Config\n    from helping_hands.lib.hands.v1.hand import (\n        BasicAtomicHand,\n        BasicLangGraphHand,\n        CodexCLIHand,\n        E2EHand,\n    )\n    from helping_hands.lib.repo import RepoIndex\n\n    task_id = getattr(getattr(self, \"request\", None), \"id\", None)\n    requested_backend, runtime_backend = _normalize_backend(backend)\n    resolved_iterations = max(1, int(max_iterations))\n    updates: list[str] = []\n    _append_update(\n        updates,\n        (\n            f\"Task received. backend={requested_backend}, model={model or 'default'}, \"\n            f\"repo={repo_path}, max_iterations={resolved_iterations}, no_pr={no_pr}\"\n        ),\n    )\n    _update_progress(\n        self,\n        task_id=task_id,\n        stage=\"starting\",\n        updates=updates,\n        backend=requested_backend,\n        runtime_backend=runtime_backend,\n        repo_path=repo_path,\n        model=model,\n        max_iterations=resolved_iterations,\n        no_pr=no_pr,\n    )\n\n    if runtime_backend == \"e2e\":\n        config = Config.from_env(overrides={\"repo\": repo_path, \"model\": model})\n        repo_index = RepoIndex(root=Path(config.repo or \".\"), files=[])\n        hand = E2EHand(config, repo_index)\n        _append_update(updates, \"Running E2E hand.\")\n        _update_progress(\n            self,\n            task_id=task_id,\n            stage=\"running\",\n            updates=updates,\n            backend=requested_backend,\n            runtime_backend=runtime_backend,\n            repo_path=repo_path,\n            model=config.model,\n            max_iterations=resolved_iterations,\n            no_pr=no_pr,\n        )\n        response = hand.run(\n            prompt,\n            hand_uuid=task_id,\n            pr_number=pr_number,\n            dry_run=no_pr,\n        )\n        _append_update(updates, response.message)\n        return {\n            \"status\": \"ok\",\n            \"backend\": requested_backend,\n            \"runtime_backend\": runtime_backend,\n            \"message\": response.message,\n            \"updates\": updates,\n            **response.metadata,\n        }\n\n    try:\n        resolved_repo_path, cloned_from = _resolve_repo_path(repo_path)\n    except ValueError as exc:\n        _append_update(updates, f\"Repo resolution failed: {exc}\")\n        raise\n\n    overrides = {\"repo\": str(resolved_repo_path), \"model\": model}\n    config = Config.from_env(overrides=overrides)\n    repo_index = RepoIndex.from_path(Path(config.repo))\n\n    if cloned_from:\n        _append_update(updates, f\"Cloned {cloned_from} to {resolved_repo_path}\")\n    if runtime_backend == \"codexcli\" and not _has_codex_auth():\n        msg = (\n            \"Codex authentication is missing in worker runtime. \"\n            \"Set OPENAI_API_KEY in .env and recreate containers, \"\n            \"or run `codex login` in the worker environment.\"\n        )\n        _append_update(updates, msg)\n        raise RuntimeError(msg)\n    _append_update(\n        updates,\n        (\n            f\"Running hand. backend={requested_backend} \"\n            f\"(runtime={runtime_backend}), model={config.model}\"\n        ),\n    )\n    _update_progress(\n        self,\n        task_id=task_id,\n        stage=\"running\",\n        updates=updates,\n        backend=requested_backend,\n        runtime_backend=runtime_backend,\n        repo_path=repo_path,\n        model=config.model,\n        max_iterations=resolved_iterations,\n        no_pr=no_pr,\n        workspace=str(resolved_repo_path),\n    )\n\n    try:\n        if runtime_backend == \"basic-langgraph\":\n            hand = BasicLangGraphHand(\n                config,\n                repo_index,\n                max_iterations=resolved_iterations,\n            )\n        elif runtime_backend == \"codexcli\":\n            hand = CodexCLIHand(\n                config,\n                repo_index,\n            )\n        else:\n            hand = BasicAtomicHand(\n                config,\n                repo_index,\n                max_iterations=resolved_iterations,\n            )\n    except ModuleNotFoundError as exc:\n        if runtime_backend == \"basic-langgraph\":\n            extra = \"langchain\"\n        elif runtime_backend in {\"basic-atomic\", \"basic-agent\"}:\n            extra = \"atomic\"\n        else:\n            extra = None\n        if extra:\n            install_hint = f\"Install with: uv sync --extra {extra}\"\n        else:\n            install_hint = \"Check runtime setup.\"\n        msg = (\n            f\"Missing dependency for backend {requested_backend}: {exc}. {install_hint}\"\n        )\n        _append_update(updates, msg)\n        raise RuntimeError(msg) from exc\n\n    hand.auto_pr = not no_pr\n    message = asyncio.run(\n        _collect_stream(\n            hand,\n            prompt,\n            task=self,\n            task_id=task_id,\n            updates=updates,\n            backend=requested_backend,\n            runtime_backend=runtime_backend,\n            repo_path=repo_path,\n            model=config.model,\n            max_iterations=resolved_iterations,\n            no_pr=no_pr,\n            workspace=str(resolved_repo_path),\n        )\n    )\n    _append_update(updates, \"Task complete.\")\n    return {\n        \"status\": \"ok\",\n        \"backend\": requested_backend,\n        \"runtime_backend\": runtime_backend,\n        \"repo\": repo_path,\n        \"workspace\": str(resolved_repo_path),\n        \"model\": config.model,\n        \"max_iterations\": str(resolved_iterations),\n        \"no_pr\": str(no_pr).lower(),\n        \"message\": message,\n        \"updates\": updates,\n    }\n</code></pre>"},{"location":"api/server/mcp_server/","title":"server.mcp_server","text":""},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server","title":"<code>helping_hands.server.mcp_server</code>","text":"<p>MCP server for helping_hands.</p> <p>Exposes repo-building capabilities over the Model Context Protocol so AI clients (Claude Desktop, Cursor, etc.) can use helping_hands as a tool provider.</p> Tools <ul> <li>index_repo: Walk a local repo and return its file listing.</li> <li>build_feature: (async via Celery) Enqueue a hand task.</li> <li>get_task_status: Check the status of an enqueued task.</li> <li>read_file: Read a UTF-8 file from a repository.</li> <li>write_file: Write a UTF-8 file in a repository.</li> <li>mkdir: Create a directory in a repository.</li> <li>path_exists: Check whether a repo-relative path exists.</li> </ul> Resources <ul> <li>repo://{path}: Read a file from an indexed repo.</li> </ul> Run with <p>uv run helping-hands-mcp          (stdio, for Claude Desktop / Cursor) uv run helping-hands-mcp --http   (streamable-http, for networked clients)</p>"},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server.index_repo","title":"<code>index_repo(repo_path)</code>","text":"<p>Index a local git repository and return its file listing.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>str</code> <p>Absolute path to the repository on disk.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dict with root path, file count, and first 200 file paths.</p> Source code in <code>src/helping_hands/server/mcp_server.py</code> <pre><code>@mcp.tool()\ndef index_repo(repo_path: str) -&gt; dict:\n    \"\"\"Index a local git repository and return its file listing.\n\n    Args:\n        repo_path: Absolute path to the repository on disk.\n\n    Returns:\n        Dict with root path, file count, and first 200 file paths.\n    \"\"\"\n    path = Path(repo_path).resolve()\n    idx = RepoIndex.from_path(path)\n    _indexed_repos[str(path)] = idx\n    return {\n        \"root\": str(idx.root),\n        \"file_count\": len(idx.files),\n        \"files\": idx.files[:200],\n    }\n</code></pre>"},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server.build_feature","title":"<code>build_feature(repo_path, prompt, pr_number=None, backend='e2e', model=None, max_iterations=6, no_pr=False)</code>","text":"<p>Enqueue a hand task via Celery and return the task ID.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>str</code> <p>Local path or GitHub repo reference in <code>owner/repo</code> format.</p> required <code>prompt</code> <code>str</code> <p>Description of the feature or change to build.</p> required <code>pr_number</code> <code>int | None</code> <p>Optional existing PR number to resume/update.</p> <code>None</code> <code>backend</code> <code>str</code> <p>One of e2e/basic-langgraph/basic-atomic/basic-agent.</p> <code>'e2e'</code> <code>model</code> <code>str | None</code> <p>Optional model override.</p> <code>None</code> <code>max_iterations</code> <code>int</code> <p>Iteration cap for basic backends.</p> <code>6</code> <code>no_pr</code> <code>bool</code> <p>Disable final PR push/create side effects.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dict with task_id and status.</p> Source code in <code>src/helping_hands/server/mcp_server.py</code> <pre><code>@mcp.tool()\ndef build_feature(\n    repo_path: str,\n    prompt: str,\n    pr_number: int | None = None,\n    backend: str = \"e2e\",\n    model: str | None = None,\n    max_iterations: int = 6,\n    no_pr: bool = False,\n) -&gt; dict:\n    \"\"\"Enqueue a hand task via Celery and return the task ID.\n\n    Args:\n        repo_path: Local path or GitHub repo reference in `owner/repo` format.\n        prompt: Description of the feature or change to build.\n        pr_number: Optional existing PR number to resume/update.\n        backend: One of e2e/basic-langgraph/basic-atomic/basic-agent.\n        model: Optional model override.\n        max_iterations: Iteration cap for basic backends.\n        no_pr: Disable final PR push/create side effects.\n\n    Returns:\n        Dict with task_id and status.\n    \"\"\"\n    from helping_hands.server.celery_app import (\n        build_feature as celery_build,\n    )\n\n    task = celery_build.delay(\n        repo_path=repo_path,\n        prompt=prompt,\n        pr_number=pr_number,\n        backend=backend,\n        model=model,\n        max_iterations=max_iterations,\n        no_pr=no_pr,\n    )\n    return {\"task_id\": task.id, \"status\": \"queued\", \"backend\": backend}\n</code></pre>"},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server.get_task_status","title":"<code>get_task_status(task_id)</code>","text":"<p>Check the status of a previously enqueued build task.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>str</code> <p>The Celery task ID returned by build_feature.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dict with task_id, status, and result (if complete).</p> Source code in <code>src/helping_hands/server/mcp_server.py</code> <pre><code>@mcp.tool()\ndef get_task_status(task_id: str) -&gt; dict:\n    \"\"\"Check the status of a previously enqueued build task.\n\n    Args:\n        task_id: The Celery task ID returned by build_feature.\n\n    Returns:\n        Dict with task_id, status, and result (if complete).\n    \"\"\"\n    from helping_hands.server.celery_app import (\n        build_feature as celery_build,\n    )\n\n    result = celery_build.AsyncResult(task_id)\n    raw_result = result.result if result.ready() else result.info\n    return {\n        \"task_id\": task_id,\n        \"status\": result.status,\n        \"result\": normalize_task_result(result.status, raw_result),\n    }\n</code></pre>"},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server.read_file","title":"<code>read_file(repo_path, file_path, max_chars=None)</code>","text":"<p>Read a file from a repository.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>str</code> <p>Absolute path to the repository root.</p> required <code>file_path</code> <code>str</code> <p>Path relative to the repo root.</p> required <code>max_chars</code> <code>int | None</code> <p>Optional max number of chars to return.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The file contents as a string.</p> Source code in <code>src/helping_hands/server/mcp_server.py</code> <pre><code>@mcp.tool()\ndef read_file(repo_path: str, file_path: str, max_chars: int | None = None) -&gt; str:\n    \"\"\"Read a file from a repository.\n\n    Args:\n        repo_path: Absolute path to the repository root.\n        file_path: Path relative to the repo root.\n        max_chars: Optional max number of chars to return.\n\n    Returns:\n        The file contents as a string.\n    \"\"\"\n    root = _repo_root(repo_path)\n    try:\n        text, _, _ = fs_tools.read_text_file(root, file_path, max_chars=max_chars)\n    except ValueError as exc:\n        msg = f\"Invalid file path: {file_path}\"\n        raise ValueError(msg) from exc\n    except FileNotFoundError as exc:\n        msg = f\"File not found: {file_path}\"\n        raise FileNotFoundError(msg) from exc\n    except IsADirectoryError as exc:\n        msg = f\"Path is a directory: {file_path}\"\n        raise IsADirectoryError(msg) from exc\n    except UnicodeError as exc:\n        msg = f\"File is not UTF-8 text: {file_path}\"\n        raise UnicodeError(msg) from exc\n    return text\n</code></pre>"},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server.write_file","title":"<code>write_file(repo_path, file_path, content)</code>","text":"<p>Write a UTF-8 file in a repository.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>str</code> <p>Absolute path to the repository root.</p> required <code>file_path</code> <code>str</code> <p>Path relative to the repo root.</p> required <code>content</code> <code>str</code> <p>Full file contents to write.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dict with normalized path and byte length.</p> Source code in <code>src/helping_hands/server/mcp_server.py</code> <pre><code>@mcp.tool()\ndef write_file(repo_path: str, file_path: str, content: str) -&gt; dict:\n    \"\"\"Write a UTF-8 file in a repository.\n\n    Args:\n        repo_path: Absolute path to the repository root.\n        file_path: Path relative to the repo root.\n        content: Full file contents to write.\n\n    Returns:\n        Dict with normalized path and byte length.\n    \"\"\"\n    root = _repo_root(repo_path)\n    try:\n        written_path = fs_tools.write_text_file(root, file_path, content)\n    except ValueError as exc:\n        msg = f\"Invalid file path: {file_path}\"\n        raise ValueError(msg) from exc\n    return {\"path\": written_path, \"bytes\": len(content.encode(\"utf-8\"))}\n</code></pre>"},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server.mkdir","title":"<code>mkdir(repo_path, dir_path)</code>","text":"<p>Create a directory in a repository.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>str</code> <p>Absolute path to the repository root.</p> required <code>dir_path</code> <code>str</code> <p>Directory path relative to the repo root.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dict with normalized created path.</p> Source code in <code>src/helping_hands/server/mcp_server.py</code> <pre><code>@mcp.tool()\ndef mkdir(repo_path: str, dir_path: str) -&gt; dict:\n    \"\"\"Create a directory in a repository.\n\n    Args:\n        repo_path: Absolute path to the repository root.\n        dir_path: Directory path relative to the repo root.\n\n    Returns:\n        Dict with normalized created path.\n    \"\"\"\n    root = _repo_root(repo_path)\n    try:\n        created = fs_tools.mkdir_path(root, dir_path)\n    except ValueError as exc:\n        msg = f\"Invalid directory path: {dir_path}\"\n        raise ValueError(msg) from exc\n    return {\"path\": created}\n</code></pre>"},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server.path_exists","title":"<code>path_exists(repo_path, path)</code>","text":"<p>Check whether a repo-relative path exists.</p> Source code in <code>src/helping_hands/server/mcp_server.py</code> <pre><code>@mcp.tool()\ndef path_exists(repo_path: str, path: str) -&gt; bool:\n    \"\"\"Check whether a repo-relative path exists.\"\"\"\n    root = _repo_root(repo_path)\n    return fs_tools.path_exists(root, path)\n</code></pre>"},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server.get_config","title":"<code>get_config()</code>","text":"<p>Return the current helping_hands configuration (from env vars).</p> Source code in <code>src/helping_hands/server/mcp_server.py</code> <pre><code>@mcp.tool()\ndef get_config() -&gt; dict:\n    \"\"\"Return the current helping_hands configuration (from env vars).\"\"\"\n    cfg = Config.from_env()\n    return {\n        \"model\": cfg.model,\n        \"verbose\": cfg.verbose,\n        \"repo\": cfg.repo or None,\n    }\n</code></pre>"},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server.list_indexed_repos","title":"<code>list_indexed_repos()</code>","text":"<p>List all currently indexed repositories.</p> Source code in <code>src/helping_hands/server/mcp_server.py</code> <pre><code>@mcp.resource(\"repo://indexed\")\ndef list_indexed_repos() -&gt; str:\n    \"\"\"List all currently indexed repositories.\"\"\"\n    if not _indexed_repos:\n        return \"No repositories indexed yet. Use the index_repo tool first.\"\n    lines = [\n        f\"- {root} ({len(idx.files)} files)\" for root, idx in _indexed_repos.items()\n    ]\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/server/mcp_server/#helping_hands.server.mcp_server.main","title":"<code>main()</code>","text":"<p>Entry point for the MCP server.</p> Source code in <code>src/helping_hands/server/mcp_server.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Entry point for the MCP server.\"\"\"\n    transport = \"streamable-http\" if \"--http\" in sys.argv else \"stdio\"\n    mcp.run(transport=transport)\n</code></pre>"},{"location":"api/server/task_result/","title":"server.task_result","text":""},{"location":"api/server/task_result/#helping_hands.server.task_result","title":"<code>helping_hands.server.task_result</code>","text":"<p>Task result normalization helpers for server and MCP endpoints.</p>"},{"location":"api/server/task_result/#helping_hands.server.task_result.normalize_task_result","title":"<code>normalize_task_result(status, raw_result)</code>","text":"<p>Normalize Celery task results into JSON-serializable dicts.</p> <p>Celery can return non-dict objects (including exception instances) for failed tasks. API surfaces should return structured JSON payloads instead of leaking non-serializable objects.</p> Source code in <code>src/helping_hands/server/task_result.py</code> <pre><code>def normalize_task_result(status: str, raw_result: Any) -&gt; dict[str, Any] | None:\n    \"\"\"Normalize Celery task results into JSON-serializable dicts.\n\n    Celery can return non-dict objects (including exception instances) for\n    failed tasks. API surfaces should return structured JSON payloads instead\n    of leaking non-serializable objects.\n    \"\"\"\n    if raw_result is None:\n        return None\n    if isinstance(raw_result, dict):\n        return raw_result\n    if isinstance(raw_result, BaseException):\n        return {\n            \"error\": str(raw_result),\n            \"error_type\": type(raw_result).__name__,\n            \"status\": status,\n        }\n    return {\n        \"value\": str(raw_result),\n        \"value_type\": type(raw_result).__name__,\n        \"status\": status,\n    }\n</code></pre>"}]}